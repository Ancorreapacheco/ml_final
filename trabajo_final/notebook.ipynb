{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df)/24)-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in range(0,87502,24): #Para que la ventana se mueva cada 24 horas\n",
    "  print(start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye un modelo Multilayer Perceptron (MLP) para regresión\n",
    "\n",
    "def build_mlp_model(input_dim, hidden_layers, activation='relu', learning_rate=0.001, kernel_regularizer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation, kernel_regularizer=kernel_regularizer))\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation=activation, kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Construye un modelo RNN simple con una sola capa recurrente\n",
    "\n",
    "def build_rnn_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Construye un modelo LSTM para capturar relaciones temporales largas\n",
    "\n",
    "def build_lstm_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Genera secuencias de datos para modelos RNN o LSTM\n",
    "\n",
    "def create_rnn_sequences(df, target_col, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        seq = df.iloc[i:i+window_size]\n",
    "        X.append(seq.drop(columns=[target_col]).values)\n",
    "        y.append(df.iloc[i+window_size][target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Función principal para entrenamiento y evaluación de MLP, RNN y LSTM con sliding windows\n",
    "\n",
    "def sliding_window_regression_models_scaling_keras_rnn(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14],\n",
    "    test_window=1,\n",
    "    #model_types=['MLP', 'RNN', 'LSTM'],\n",
    "    model_types=['MLP'],\n",
    "    mlp_params = {\n",
    "        'hidden_layers': [[64], [32], [64, 32]],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001, 0.01],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "        'kernel_regularizer': [l2(0.001), l2(0.01)]\n",
    "    },\n",
    "    rnn_params={\n",
    "        'hidden_units': [16, 32],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    lstm_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso_keras_rnn'\n",
    "):\n",
    "    # Crea carpeta de resultados si no existe\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    # Itera sobre diferentes ventanas de entrenamiento T\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\", unit=\"ventana\"):\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - T_hours - test_hours + 1\n",
    "        output_path = os.path.join(save_path, f'ANN_resultados_T{T}.csv')\n",
    "\n",
    "        # Carga resultados previos si existen para evitar cálculos redundantes\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # Itera sobre MLP, RNN o LSTM\n",
    "        for model_type in model_types:\n",
    "            if model_type == 'MLP':\n",
    "                param_grid = list(product(*mlp_params.values()))\n",
    "                param_keys = list(mlp_params.keys())\n",
    "            elif model_type == 'RNN':\n",
    "                param_grid = list(product(*rnn_params.values()))\n",
    "                param_keys = list(rnn_params.keys())\n",
    "            elif model_type == 'LSTM':\n",
    "                param_grid = list(product(*lstm_params.values()))\n",
    "                param_keys = list(lstm_params.keys())\n",
    "\n",
    "            # Itera sobre combinaciones de hiperparámetros\n",
    "            for combo in param_grid:\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                print(f\"🔧 Evaluando modelo {model_type} con hiperparámetros: {param_dict}\")\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                if not df_prev.empty and ((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict))).any():\n",
    "                    continue\n",
    "\n",
    "                resultados = {k: [] for k in ['MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p']}\n",
    "\n",
    "                # Sliding window sobre el conjunto de datos\n",
    "                for start in range(0, total_windows, 24):\n",
    "                    if model_type == 'MLP':\n",
    "                        train = df.iloc[start: start + T_hours]\n",
    "                        test = df.iloc[start + T_hours: start + T_hours + test_hours]\n",
    "\n",
    "                        X_train = train.drop(columns=[target_col])\n",
    "                        y_train = train[target_col]\n",
    "                        X_test = test.drop(columns=[target_col])\n",
    "                        y_test = test[target_col]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train = scaler.fit_transform(X_train)\n",
    "                        X_test = scaler.transform(X_test)\n",
    "\n",
    "                        model = build_mlp_model(\n",
    "                            input_dim=X_train.shape[1],\n",
    "                            hidden_layers=param_dict['hidden_layers'],\n",
    "                            activation=param_dict['activation'],\n",
    "                            learning_rate=param_dict['learning_rate'],\n",
    "                            kernel_regularizer=param_dict['kernel_regularizer']\n",
    "                        )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    else:\n",
    "                        # Escalamiento sin data leakage para RNN/LSTM\n",
    "                        data_window = df.iloc[start: start + T_hours + test_hours].copy()\n",
    "                        train_data = data_window.iloc[:T_hours]\n",
    "                        test_data = data_window.iloc[T_hours:]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_scaled = scaler.fit_transform(train_data.drop(columns=[target_col]))\n",
    "                        X_test_scaled = scaler.transform(test_data.drop(columns=[target_col]))\n",
    "\n",
    "                        train_scaled = pd.DataFrame(X_train_scaled, columns=train_data.columns.drop(target_col))\n",
    "                        train_scaled[target_col] = train_data[target_col].values\n",
    "\n",
    "                        test_scaled = pd.DataFrame(X_test_scaled, columns=test_data.columns.drop(target_col))\n",
    "                        test_scaled[target_col] = test_data[target_col].values\n",
    "\n",
    "                        scaled = pd.concat([train_scaled, test_scaled])\n",
    "                        X, y = create_rnn_sequences(scaled, target_col, T_hours)\n",
    "                        X_train, y_train = X[:-1], y[:-1]\n",
    "                        X_test, y_test = X[-1:], y[-1:]\n",
    "\n",
    "                        if model_type == 'RNN':\n",
    "                            model = build_rnn_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "                        else:  # LSTM\n",
    "                            model = build_lstm_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    # Cálculo de métricas\n",
    "                    residuals = y_test.values - y_pred if hasattr(y_test, 'values') else y_test - y_pred\n",
    "                    resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                    resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                    resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                    resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                    resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "                    if model_type == 'MLP' and len(residuals) >= 2:\n",
    "                        ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                    else:\n",
    "                        ljung_p = np.nan\n",
    "                    resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "                # Registro y guardado de resultados por combinación\n",
    "                nuevo_row = pd.DataFrame([{\n",
    "                    'modelo': model_type,\n",
    "                    'params': param_dict,\n",
    "                    'T_dias': T,\n",
    "                    'T_horas': T_hours,\n",
    "                    'MAPE': np.mean(resultados['MAPE']),\n",
    "                    'MAE': np.mean(resultados['MAE']),\n",
    "                    'RMSE': np.mean(resultados['RMSE']),\n",
    "                    'MSE': np.mean(resultados['MSE']),\n",
    "                    'R2': np.mean(resultados['R2']),\n",
    "                    'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "                }])\n",
    "                df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "                print(f\"✅ Finalizado {model_type} con RMSE promedio: {np.mean(resultados['RMSE']):.4f}\")\n",
    "                df_prev.to_csv(output_path, index=False)\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "\n",
    "    return resultados_por_T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
