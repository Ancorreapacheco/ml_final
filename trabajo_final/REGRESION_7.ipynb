{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA (UTC)</th>\n",
       "      <th>VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))</th>\n",
       "      <th>VENTO, VELOCIDADE HORARIA (m/s)</th>\n",
       "      <th>UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>UMIDADE RELATIVA DO AR, HORARIA (%)</th>\n",
       "      <th>PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)</th>\n",
       "      <th>PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)</th>\n",
       "      <th>VENTO, RAJADA MAXIMA (m/s)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HORA (UTC)  VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))  \\\n",
       "0      12:00                                    0.809017   \n",
       "\n",
       "   VENTO, VELOCIDADE HORARIA (m/s)  UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)  \\\n",
       "0                              1.8                                      69.0   \n",
       "\n",
       "   UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)  \\\n",
       "0                                      60.0   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            22.6   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            20.7   \n",
       "\n",
       "   UMIDADE RELATIVA DO AR, HORARIA (%)  \\\n",
       "0                                 61.0   \n",
       "\n",
       "   PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)  \\\n",
       "0                                              888.2       \n",
       "\n",
       "   PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)  VENTO, RAJADA MAXIMA (m/s)  \\\n",
       "0                                     0.0                         3.8   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)  \\\n",
       "0                                              888.2   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)  \n",
       "0                                              887.7   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA</th>\n",
       "      <th>WIND_DIR_HOR</th>\n",
       "      <th>WIND_VEL_HOR</th>\n",
       "      <th>HUM_REL_MAX_ANT</th>\n",
       "      <th>HUM_REL_MIN_ANT</th>\n",
       "      <th>TEMP_MAX_ANT</th>\n",
       "      <th>TEMP_MIN_ANT</th>\n",
       "      <th>HUM_REL_HOR</th>\n",
       "      <th>PRES_ATM_NIV</th>\n",
       "      <th>PREC_HOR</th>\n",
       "      <th>RAFAGA_VIENTO</th>\n",
       "      <th>PRES_ATM_MAX_ANT</th>\n",
       "      <th>PRES_ATM_MIN_ANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13:00</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>888.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>888.4</td>\n",
       "      <td>888.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HORA  WIND_DIR_HOR  WIND_VEL_HOR  HUM_REL_MAX_ANT  HUM_REL_MIN_ANT  \\\n",
       "0  12:00      0.809017           1.8             69.0             60.0   \n",
       "1  13:00      0.965926           2.7             62.0             55.0   \n",
       "\n",
       "   TEMP_MAX_ANT  TEMP_MIN_ANT  HUM_REL_HOR  PRES_ATM_NIV  PREC_HOR  \\\n",
       "0          22.6          20.7         61.0         888.2       0.0   \n",
       "1          24.2          22.5         55.0         888.4       0.0   \n",
       "\n",
       "   RAFAGA_VIENTO  PRES_ATM_MAX_ANT  PRES_ATM_MIN_ANT  \n",
       "0            3.8             888.2             887.7  \n",
       "1            4.7             888.4             888.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_lagged_features(\n",
    "    df: pd.DataFrame,\n",
    "    response_col: str,\n",
    "    num_lags: int,\n",
    "    response_shift: int = 0,\n",
    "    output_path: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con caracterÃ­sticas de retardo (lag features) para modelado,\n",
    "    y opcionalmente lo exporta a un archivo Excel, permitiendo desplazar la variable de respuesta.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original que contiene las columnas de respuesta y predictoras.\n",
    "        El Ã­ndice debe estar ordenado temporalmente.\n",
    "\n",
    "    response_col : str\n",
    "        Nombre de la columna que se utilizarÃ¡ como variable de respuesta.\n",
    "\n",
    "    num_lags : int\n",
    "        NÃºmero de perÃ­odos de retardo a considerar para las caracterÃ­sticas.\n",
    "\n",
    "    response_shift : int, opcional (por defecto 0)\n",
    "        NÃºmero de perÃ­odos para desplazar la variable de respuesta.\n",
    "        - Si es positivo, desplaza la respuesta hacia el futuro (predice el futuro).\n",
    "        - Si es negativo, desplaza la respuesta hacia el pasado.\n",
    "        - Si es 0, no se desplaza la respuesta.\n",
    "\n",
    "    output_path : str, opcional (por defecto None)\n",
    "        Ruta completa donde se exportarÃ¡ el DataFrame resultante en formato Excel.\n",
    "        Si es None, no se exportarÃ¡ el archivo.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las caracterÃ­sticas de retardo y la variable de respuesta.\n",
    "        Las filas con valores faltantes serÃ¡n eliminadas.\n",
    "    \"\"\"\n",
    "\n",
    "    if response_col not in df.columns:\n",
    "        raise ValueError(f\"La columna de respuesta '{response_col}' no estÃ¡ en el DataFrame.\")\n",
    "\n",
    "    # Determinar automÃ¡ticamente las columnas predictoras\n",
    "    predictor_cols = df.columns.drop(response_col)\n",
    "\n",
    "    # Crear DataFrame para caracterÃ­sticas de retardo\n",
    "    lag_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in predictor_cols:\n",
    "        for lag in range(1, num_lags + 1):\n",
    "            lag_features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    final_df = lag_features.copy()\n",
    "\n",
    "    # Agregar variable de respuesta desplazada\n",
    "    if response_shift != 0:\n",
    "        final_df[response_col] = df[response_col].shift(-response_shift + 1)\n",
    "    else:\n",
    "        final_df[response_col] = df[response_col]\n",
    "\n",
    "    # Eliminar valores faltantes y resetear Ã­ndice\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Exportar si se especifica una ruta\n",
    "    if output_path:\n",
    "        try:\n",
    "            directory = os.path.dirname(output_path)\n",
    "            if directory:\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "            final_df.to_excel(output_path, index=False)\n",
    "            print(f\"El DataFrame con caracterÃ­sticas de retardo ha sido exportado exitosamente a: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al exportar el DataFrame a Excel: {e}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 15, 50, 100], 'min_samples_leaf': [1, 10, 20]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': None},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100, 500], 'max_depth': [5, 10, 20], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01, 0.1], 'n_estimators': [100, 500]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nðŸ§ª Ventana T = {T} dÃ­as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'ðŸ˜Ž Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # âš¡ Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # ðŸ§  Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # ðŸ” Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"âœ“ Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"ðŸ“¦ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"âœ” Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ad59ac27cc44c7976c8aed60d4f1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando T:   0%|          | 0/1 [00:00<?, ?ventana/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Ventana T = 7 dÃ­as\n",
      "ðŸ˜Ž Total windows 87334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebe545a4e2341b996e3aba5939be8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando splits:   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a90c57f4a04890874237352bcd1df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Construyendo modelos:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d729eff7375e473c915a77dd94341ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluando modelos:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Modelo lr con True ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.01, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.01, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.1, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.1, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.5, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 0.5, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 1.0, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 1.0, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 10.0, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo ridge con {'alpha': 10.0, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.01, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.01, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.1, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.1, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.5, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 0.5, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 1.0, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 1.0, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 10.0, 'fit_intercept': True} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo lasso con {'alpha': 10.0, 'fit_intercept': False} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 5, 'min_samples_leaf': 1} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 5, 'min_samples_leaf': 3} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 5, 'min_samples_leaf': 5} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 5, 'min_samples_leaf': 10} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 10, 'min_samples_leaf': 1} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 10, 'min_samples_leaf': 3} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 10, 'min_samples_leaf': 5} ya evaluado para T=7. Saltando...\n",
      "âœ“ Modelo tree_regressor con {'max_depth': 10, 'min_samples_leaf': 10} ya evaluado para T=7. Saltando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6f49a9df4b42d8a46eabecb917071c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 15, 'min_samples_leaf': 1} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808f6d172011450bb4a531ad2bfff7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 15, 'min_samples_leaf': 3} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7614f824a754867bce2777a5718b4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 15, 'min_samples_leaf': 5} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca30e3eebf4745f8a8f7c65b812c259d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 15, 'min_samples_leaf': 10} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9997406f599a450c97ec4f3e43379e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 30, 'min_samples_leaf': 1} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982193ef13754751bec73c420751a290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 30, 'min_samples_leaf': 3} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e6ffc41d77469fa8974ce95c8f795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 30, 'min_samples_leaf': 5} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc374dfe954b019340dfbbe1906e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tree_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo tree_regressor con {'max_depth': 30, 'min_samples_leaf': 10} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8b4602041247f9a9661b5a9a11e862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ramdon_forest (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo ramdon_forest con {'n_estimators': 100, 'max_depth': 5, 'n_jobs': -1} en T=7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f7e748162a4b4e8846bceec3479b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xgb_regressor (T=7d):   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Guardado modelo xgb_regressor con {'random_state': 0, 'learning_rate': 0.01, 'n_estimators': 100} en T=7\n",
      "âœ” Resultados finales guardados en: ./progreso\\resultados_T7.csv\n"
     ]
    }
   ],
   "source": [
    "results = sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15, 30], 'min_samples_leaf': [1, 3, 5, 10]}},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100], 'max_depth': [5], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01], 'n_estimators': [100]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TEMP_MAX_ANT_lag_184'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\frame.py:4485\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value, refs)\u001b[0m\n\u001b[0;32m   4484\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TEMP_MAX_ANT_lag_184'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,total_windows,\u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m     21\u001b[0m     data_window \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start: start \u001b[38;5;241m+\u001b[39m (T_hours \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m test_hours]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 22\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_shifted_lagged_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresponse_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT_hours\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresponse_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     splits\u001b[38;5;241m.\u001b[39mappend(temp_df)\n\u001b[0;32m     25\u001b[0m splits[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m, in \u001b[0;36mcreate_shifted_lagged_features\u001b[1;34m(df, response_col, num_lags, response_shift, output_path)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m predictor_cols:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_lags \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m         \u001b[43mlag_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_lag_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mshift(lag)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Construir DataFrame final\u001b[39;00m\n\u001b[0;32m     55\u001b[0m final_df \u001b[38;5;241m=\u001b[39m lag_features\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4535\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   4536\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 4538\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\frame.py:4488\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value, refs)\u001b[0m\n\u001b[0;32m   4485\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4487\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 4488\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1385\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_update_mgr_locs(loc)\n\u001b[1;32m-> 1385\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_insert_update_blklocs_and_blknos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_axis\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (block,)\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1422\u001b[0m, in \u001b[0;36mBlockManager._insert_update_blklocs_and_blknos\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1422\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blknos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;66;03m# np.append is a lot faster, let's use it if we can.\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\numpy\\lib\\function_base.py:5618\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" df_temp = df.iloc[0:(24*7)*2]\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "num_lags = 24*7\n",
    "lagged = create_shifted_lagged_features(df_temp,response_col,num_lags,response_shift=1)\n",
    "lagged.to_csv('./lagged.csv', index=False)\n",
    "\n",
    "#T =[7,14,21]\n",
    "T =[14,21]\n",
    "test_window = 1\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "for t in T:\n",
    "  # Definir la ventana de tiempo para el entrenamiento y la prueba\n",
    "  T_hours = t * 24\n",
    "  test_hours = test_window * 24\n",
    "  extra = 24 #1 dia adicional para el test\n",
    "  total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "\n",
    "\n",
    "  splits=[]\n",
    "  for start in range(0,total_windows,24):\n",
    "    data_window = df.iloc[start: start + (T_hours * 2) + test_hours].copy()\n",
    "    temp_df = create_shifted_lagged_features(data_window,response_col,num_lags=T_hours,response_shift=1)\n",
    "    splits.append(temp_df)\n",
    "  \n",
    "splits[0].shape \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
