{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESI√ìN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funci√≥n genera lag features, es decir, que representan el valor de la variables predictoras en periodos anteriores. Lo anterior es √∫til para predecir el valor de la variable dependiente en un periodo futuro. El formato de salida de la funci√≥n es tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_lagged_features(\n",
    "    df: pd.DataFrame,\n",
    "    response_col: str,\n",
    "    num_lags: int,\n",
    "    response_shift: int = 0,\n",
    "    output_path: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con caracter√≠sticas de retardo (lag features) para modelado,\n",
    "    y opcionalmente lo exporta a un archivo Excel, permitiendo desplazar la variable de respuesta.\n",
    "\n",
    "    Par√°metros:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original que contiene las columnas de respuesta y predictoras.\n",
    "        El √≠ndice debe estar ordenado temporalmente.\n",
    "\n",
    "    response_col : str\n",
    "        Nombre de la columna que se utilizar√° como variable de respuesta.\n",
    "\n",
    "    num_lags : int\n",
    "        N√∫mero de per√≠odos de retardo a considerar para las caracter√≠sticas.\n",
    "\n",
    "    response_shift : int, opcional (por defecto 0)\n",
    "        N√∫mero de per√≠odos para desplazar la variable de respuesta.\n",
    "        - Si es positivo, desplaza la respuesta hacia el futuro (predice el futuro).\n",
    "        - Si es negativo, desplaza la respuesta hacia el pasado.\n",
    "        - Si es 0, no se desplaza la respuesta.\n",
    "\n",
    "    output_path : str, opcional (por defecto None)\n",
    "        Ruta completa donde se exportar√° el DataFrame resultante en formato Excel.\n",
    "        Si es None, no se exportar√° el archivo.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las caracter√≠sticas de retardo y la variable de respuesta.\n",
    "        Las filas con valores faltantes ser√°n eliminadas.\n",
    "    \"\"\"\n",
    "\n",
    "    if response_col not in df.columns:\n",
    "        raise ValueError(f\"La columna de respuesta '{response_col}' no est√° en el DataFrame.\")\n",
    "\n",
    "    # Determinar autom√°ticamente las columnas predictoras\n",
    "    predictor_cols = df.columns.drop(response_col)\n",
    "\n",
    "    # Crear DataFrame para caracter√≠sticas de retardo\n",
    "    lag_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in predictor_cols:\n",
    "        for lag in range(1, num_lags + 1):\n",
    "            lag_features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    final_df = lag_features.copy()\n",
    "\n",
    "    # Agregar variable de respuesta desplazada\n",
    "    if response_shift != 0:\n",
    "        final_df[response_col] = df[response_col].shift(-response_shift + 1)\n",
    "    else:\n",
    "        final_df[response_col] = df[response_col]\n",
    "\n",
    "    # Eliminar valores faltantes y resetear √≠ndice\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Exportar si se especifica una ruta\n",
    "    if output_path:\n",
    "        try:\n",
    "            directory = os.path.dirname(output_path)\n",
    "            if directory:\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "            final_df.to_excel(output_path, index=False)\n",
    "            print(f\"El DataFrame con caracter√≠sticas de retardo ha sido exportado exitosamente a: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al exportar el DataFrame a Excel: {e}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de regresi√≥n sin escalado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la siguiente funci√≥n se evaluan los modelos de regresi√≥n sine scalado como;\n",
    "\n",
    "- Regresi√≥n lineal\n",
    "- Regresi√≥n Ridge\n",
    "- Regresi√≥n Lasso\n",
    "- Arbol de regresi√≥n\n",
    "- Random Forest regresi√≥n\n",
    "- Gradient Boosting regresi√≥n\n",
    "\n",
    "Para cada una de las ventanas (7,14 y 21) se almacenas los resultadoos de las metricas solicitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 15, 50, 100], 'min_samples_leaf': [1, 10, 20]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': None},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100, 500], 'max_depth': [5, 10, 20], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01], 'n_estimators': [100]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'reg_resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # ‚ö° Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # üß† Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # üîç Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"‚úì Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7,14,21],\n",
    "    test_window=1,\n",
    "   modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15, 30], 'min_samples_leaf': [1, 3, 5, 10]}},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100], 'max_depth': [5], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01], 'n_estimators': [100]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de regresi√≥n con escalado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la siguiente funci√≥n se evaluan los modelos de regresi√≥n que requieren escalado como;\n",
    "\n",
    "- Vecinos m√°s cercanos (KNN)\n",
    "- SVR\n",
    "\n",
    "Para cada una de las ventanas (7,14 y 21) se almacenas los resultadoos de las metricas solicitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged_scaled(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'Kneighboors', 'ModelClass': KNeighborsRegressor, 'params': {'n_neighbors': [5, 10,15], 'algorithm': ['ball_tree', 'kd_tree'], 'leaf_size':[30,60], 'n_jobs':[-1], 'weights': ['uniform', 'distance']}},\n",
    "        {'name': 'SVR', 'ModelClass': SVR, 'params': {\n",
    "          'C': [0.1, 1.0, 10],            # Regularizaci√≥n (m√°s alto = menos tolerancia al error)\n",
    "          'epsilon': [0.01, 0.1, 0.2],     # Margen de tolerancia al error sin penalizaci√≥n\n",
    "          'kernel': ['rbf','linear'],          # Funci√≥n de kernel (RBF = radial basis function, muy usada)\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f's_resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # ‚ö° Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # üß† Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # üîç Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"‚úì Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                #Escalo variables\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.fit_transform(X_test)\n",
    "                \n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_regression_models_lagged_scaled(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7,14,21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'Kneighboors', 'ModelClass': KNeighborsRegressor, 'params': {'n_neighbors': [5, 10,15], 'algorithm': ['ball_tree', 'kd_tree'], 'leaf_size':[30,60], 'n_jobs':[-1], 'weights': ['uniform', 'distance']}},\n",
    "        {'name': 'SVR', 'ModelClass': SVR, 'params': {\n",
    "          'C': [0.1, 1.0, 10],            # Regularizaci√≥n (m√°s alto = menos tolerancia al error)\n",
    "          'epsilon': [0.01, 0.1, 0.2],     # Margen de tolerancia al error sin penalizaci√≥n\n",
    "          'kernel': ['rbf','linear'],          # Funci√≥n de kernel (RBF = radial basis function, muy usada)\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento y evaluaci√≥n de los modelos de redes neuronales se realizar√° con Tensorflow y Keras utilizando GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar dispositivos disponibles\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if devices:\n",
    "    print(f\"TensorFlow est√° utilizando la GPU: {devices}\")\n",
    "else:\n",
    "    print(\"TensorFlow no est√° utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_dim, hidden_layers, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(1))  # Capa de salida (regresi√≥n)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def sliding_window_regression_models_lagged_MLP(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    save_path='./progreso',\n",
    "    mlp_params={\n",
    "        'hidden_layers': [[32], [64]],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.01],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "    },\n",
    "    model_type='mlp'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'mlp_resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        param_grid = list(product(*mlp_params.values()))\n",
    "        param_keys = list(mlp_params.keys())\n",
    "\n",
    "        #for combo in param_grid:\n",
    "        for combo in tqdm(param_grid, desc=\"Evaluando combinaciones\", unit=\"modelo\", leave=True):\n",
    "            param_dict = dict(zip(param_keys, combo))\n",
    "            ya_realizado = not df_prev.empty and ((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict))).any()\n",
    "\n",
    "            if ya_realizado:\n",
    "                rmse = df_prev[((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict)))]['RMSE'].values[0]\n",
    "                print(f\"‚è© Saltando modelo ya evaluado: {model_type} con hiperpar√°metros: {param_dict} y RMSE {rmse}\")\n",
    "                continue\n",
    "\n",
    "            modelo_idx = param_grid.index(combo) + 1\n",
    "            total_modelos = len(param_grid)\n",
    "            progreso_modelo = (modelo_idx / total_modelos) * 100\n",
    "            print(f\"\\nüîß Modelo {modelo_idx}/{total_modelos} ({progreso_modelo:.1f}%) - {model_type} con hiperpar√°metros: {param_dict}\")\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': model_type,\n",
    "                'params': param_dict,\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            #for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{model_type} {param_dict} (T={T}d)\", leave=True):\n",
    "            for X_train, y_train, X_test, y_test in tqdm(reversed(splits), desc=f\"{model_type} {param_dict} (T={T}d)\", leave=True):\n",
    "                model = build_mlp_model(\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    hidden_layers=param_dict['hidden_layers'],\n",
    "                    activation=param_dict['activation'],\n",
    "                    learning_rate=param_dict['learning_rate']\n",
    "                )\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.fit_transform(X_test)  # ‚ö†Ô∏è intencional\n",
    "\n",
    "                early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred.flatten()\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {model_type} {param_dict} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_regression_models_lagged_MLP(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7,14,21],\n",
    "    test_window=1,\n",
    "    save_path='./progreso',\n",
    "    mlp_params={\n",
    "        'hidden_layers': [[16,32],[16],[32],[64],[32,64],[16,32,64]],\n",
    "        'activation': ['tanh', 'linear', 'relu'],\n",
    "        'learning_rate': [0.01,0.1],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "    },\n",
    "    model_type='mlp'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp_7 = pd.read_csv('./progreso/mlp_resultados_T7.csv')\n",
    "df_mlp_7.sort_values(by='RMSE', ascending= True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evaluara una red de una capa con 32 neuronas variando la funci√≥n de activaci√≥n entre Tanh y Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Genera secuencias de entrenamiento para RNN y LSTM\n",
    "def create_sequences(df, target_col, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        seq = df.iloc[i:i+window_size]\n",
    "        X.append(seq.drop(columns=[target_col]).values)\n",
    "        y.append(df.iloc[i+window_size][target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# üß† Construye un modelo LSTM para dependencias temporales largas\n",
    "def build_lstm_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_lstm_only(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14,21],\n",
    "    test_window=1,\n",
    "    lstm_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    log_tiempos_path = os.path.join(save_path, 'tiempos_ejecucion.csv')\n",
    "    if not os.path.exists(log_tiempos_path):\n",
    "        with open(log_tiempos_path, 'w') as f:\n",
    "            f.write('T_dias,modelo,parametros,duracion_segundos\\n')\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\"):\n",
    "        print(f\"\\nüß≠ Iniciando evaluaci√≥n para ventana T={T} d√≠as...\")\n",
    "        inicio_ventana = time.time()\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        extra = 1 * 24  # Datos adicionales necesarios para generar las secuencias del test\n",
    "        total_windows = len(df) - T_hours - test_hours - extra + 1\n",
    "        output_path = os.path.join(save_path, f'LSTM_resultados_T{T}.csv')\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=['modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'])\n",
    "\n",
    "        param_grid = list(product(*lstm_params.values()))\n",
    "        param_keys = list(lstm_params.keys())\n",
    "        model_type = 'LSTM'\n",
    "\n",
    "        for combo in param_grid:\n",
    "            param_dict = dict(zip(param_keys, combo))\n",
    "            ya_realizado = not df_prev.empty and ((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict))).any()\n",
    "            if ya_realizado:\n",
    "                rmse = df_prev[((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict)))]['RMSE'].values[0]\n",
    "                print(f\"‚è© Saltando modelo ya evaluado: {model_type} con hiperpar√°metros: {param_dict} y RMSE {rmse}\")\n",
    "                continue\n",
    "\n",
    "            modelo_idx = param_grid.index(combo) + 1\n",
    "            total_modelos = len(param_grid)\n",
    "            progreso_modelo = (modelo_idx / total_modelos) * 100\n",
    "            print(f\"\\nüîß Modelo {modelo_idx}/{total_modelos} ({progreso_modelo:.1f}%) - {model_type} con hiperpar√°metros: {param_dict}\")\n",
    "\n",
    "            inicio_modelo = time.time()\n",
    "            resultados = {k: [] for k in ['MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p']}\n",
    "\n",
    "            for start in tqdm(range(0, total_windows, 24), desc=f\"     ‚Ü™ Subventanas ({model_type})\", leave=False):\n",
    "                # ü™ü Segmento de datos: entrenamiento + prueba + extra para completar secuencia\n",
    "                data_window = df.iloc[start: start + T_hours + test_hours + extra].copy()\n",
    "                train_data = data_window.iloc[:T_hours]\n",
    "                test_data = data_window.iloc[T_hours:]\n",
    "\n",
    "                # ‚öôÔ∏è Escalado\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(train_data.drop(columns=[target_col]))\n",
    "                X_test_scaled = scaler.fit_transform(test_data.drop(columns=[target_col]))  # ‚ö†Ô∏è intencionalmente fit_transform en ambos\n",
    "\n",
    "                train_scaled = pd.DataFrame(X_train_scaled, columns=train_data.columns.drop(target_col))\n",
    "                train_scaled[target_col] = train_data[target_col].values\n",
    "\n",
    "                test_scaled = pd.DataFrame(X_test_scaled, columns=test_data.columns.drop(target_col))\n",
    "                test_scaled[target_col] = test_data[target_col].values\n",
    "\n",
    "                # üìä Uni√≥n de train y test escalados para crear secuencias\n",
    "                scaled = pd.concat([train_scaled, test_scaled])\n",
    "\n",
    "                # üß† Creaci√≥n de secuencias tipo LSTM\n",
    "                X, y = create_sequences(scaled, target_col, T_hours)\n",
    "\n",
    "                # üèÅ Divisi√≥n expl√≠cita del test: √∫ltimos 24 pasos (1 d√≠a) como predicci√≥n\n",
    "                X_train, y_train = X[:-24], y[:-24]\n",
    "                X_test, y_test = X[-24:], y[-24:]\n",
    "\n",
    "                # üß± Modelo LSTM\n",
    "                model = build_lstm_model(\n",
    "                    timesteps=X_train.shape[1],\n",
    "                    input_dim=X_train.shape[2],\n",
    "                    hidden_units=param_dict['hidden_units'],\n",
    "                    activation=param_dict['activation'],\n",
    "                    learning_rate=param_dict['learning_rate']\n",
    "                )\n",
    "\n",
    "                early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                # üìà M√©tricas\n",
    "                residuals = y_test - y_pred\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "                ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0] if len(residuals) >= 2 else np.nan\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            # üóÉÔ∏è Guardar resultados\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': model_type,\n",
    "                'params': param_dict,\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "\n",
    "            # ‚è±Ô∏è Duraci√≥n por modelo\n",
    "            duracion = time.time() - inicio_modelo\n",
    "            with open(log_tiempos_path, 'a') as f:\n",
    "                f.write(f'{T},{model_type},\"{param_dict}\",{duracion:.2f}\\n')\n",
    "\n",
    "            print(f\"‚úÖ Finalizado {model_type} con RMSE promedio: {np.mean(resultados['RMSE']):.4f} en {duracion:.2f} segundos\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        duracion_ventana = time.time() - inicio_ventana\n",
    "        print(f\"üïí Tiempo total para T={T} d√≠as: {duracion_ventana:.2f} segundos\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_lstm_only(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14,21],\n",
    "    test_window=1,\n",
    "    lstm_params={\n",
    "        'hidden_units': [32],\n",
    "        'activation': ['tanh', 'sigmoid'],\n",
    "        'learning_rate': [0.005],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evaluaran redes neuronales de una sola capa con 32 y 64 neuronas, se variaran la funci√≥n de activaci√≥n y la rata de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Construye un modelo RNN simple\n",
    "def build_rnn_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "def sliding_window_rnn_only( \n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    rnn_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    log_tiempos_path = os.path.join(save_path, 'tiempos_ejecucion.csv')\n",
    "    if not os.path.exists(log_tiempos_path):\n",
    "        with open(log_tiempos_path, 'w') as f:\n",
    "            f.write('T_dias,modelo,parametros,duracion_segundos\\n')\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\"):\n",
    "        print(f\"\\nüß≠ Iniciando evaluaci√≥n para ventana T={T} d√≠as...\")\n",
    "        inicio_ventana = time.time()\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        extra = 1 * 24\n",
    "        total_windows = len(df) - T_hours - test_hours - extra + 1\n",
    "        output_path = os.path.join(save_path, f'RNN_resultados_T{T}.csv')\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=['modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'])\n",
    "\n",
    "        param_grid = list(product(*rnn_params.values()))\n",
    "        param_keys = list(rnn_params.keys())\n",
    "        model_type = 'RNN'\n",
    "\n",
    "        for combo in param_grid:\n",
    "            param_dict = dict(zip(param_keys, combo))\n",
    "            ya_realizado = not df_prev.empty and ((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict))).any()\n",
    "            if ya_realizado:\n",
    "                rmse = df_prev[((df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict)))]['RMSE'].values[0]\n",
    "                print(f\"‚è© Saltando modelo ya evaluado: {model_type} con hiperpar√°metros: {param_dict} y RMSE {rmse}\")\n",
    "                continue\n",
    "\n",
    "            modelo_idx = param_grid.index(combo) + 1\n",
    "            total_modelos = len(param_grid)\n",
    "            progreso_modelo = (modelo_idx / total_modelos) * 100\n",
    "            print(f\"\\nüîß Modelo {modelo_idx}/{total_modelos} ({progreso_modelo:.1f}%) - {model_type} con hiperpar√°metros: {param_dict}\")\n",
    "\n",
    "            inicio_modelo = time.time()\n",
    "            resultados = {k: [] for k in ['MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p']}\n",
    "\n",
    "            for start in tqdm(range(0, total_windows, 24), desc=f\"     ‚Ü™ Subventanas ({model_type})\", leave=False):\n",
    "                data_window = df.iloc[start: start + T_hours + test_hours + extra].copy()\n",
    "                train_data = data_window.iloc[:T_hours]\n",
    "                test_data = data_window.iloc[T_hours:]\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(train_data.drop(columns=[target_col]))\n",
    "                X_test_scaled = scaler.fit_transform(test_data.drop(columns=[target_col]))\n",
    "\n",
    "                train_scaled = pd.DataFrame(X_train_scaled, columns=train_data.columns.drop(target_col))\n",
    "                train_scaled[target_col] = train_data[target_col].values\n",
    "\n",
    "                test_scaled = pd.DataFrame(X_test_scaled, columns=test_data.columns.drop(target_col))\n",
    "                test_scaled[target_col] = test_data[target_col].values\n",
    "\n",
    "                scaled = pd.concat([train_scaled, test_scaled])\n",
    "                X, y = create_sequences(scaled, target_col, T_hours)\n",
    "                X_train, y_train = X[:-24], y[:-24]\n",
    "                X_test, y_test = X[-24:], y[-24:]\n",
    "\n",
    "                #print(f'Train set shape: {X_train.shape} y {y_train.shape}')\n",
    "                #print(f'Test set shape: {X_test.shape} y {y_test.shape}')\n",
    "\n",
    "                # üîÑ Reemplazo del modelo LSTM por RNN\n",
    "                model = build_rnn_model(\n",
    "                    timesteps=X_train.shape[1],\n",
    "                    input_dim=X_train.shape[2],\n",
    "                    hidden_units=param_dict['hidden_units'],\n",
    "                    activation=param_dict['activation'],\n",
    "                    learning_rate=param_dict['learning_rate']\n",
    "                )\n",
    "\n",
    "                early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "                ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0] if len(residuals) >= 2 else np.nan\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': model_type,\n",
    "                'params': param_dict,\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "\n",
    "            duracion = time.time() - inicio_modelo\n",
    "            with open(log_tiempos_path, 'a') as f:\n",
    "                f.write(f'{T},{model_type},\"{param_dict}\",{duracion:.2f}\\n')\n",
    "\n",
    "            print(f\"‚úÖ Finalizado {model_type} con RMSE promedio: {np.mean(resultados['RMSE']):.4f} en {duracion:.2f} segundos\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        duracion_ventana = time.time() - inicio_ventana\n",
    "        print(f\"üïí Tiempo total para T={T} d√≠as: {duracion_ventana:.2f} segundos\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_rnn_only( \n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    rnn_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'learning_rate': [0.001, 0.005],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rmse_bar(df, title='RMSE por Modelo', sort_ascending=True, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Genera una gr√°fica de barras del RMSE por modelo, ordenada seg√∫n el valor del RMSE.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame que debe contener las columnas 'modelo', 'params' y 'RMSE'.\n",
    "    - title: T√≠tulo de la gr√°fica.\n",
    "    - sort_ascending: Booleano, si True ordena de menor a mayor RMSE.\n",
    "    - figsize: Tama√±o de la figura (tupla).\n",
    "\n",
    "    Retorna:\n",
    "    - None (muestra la gr√°fica).\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(by=\"RMSE\", ascending=sort_ascending)\n",
    "    etiquetas = df_sorted['modelo'].astype(str) + ' ' + df_sorted['params'].astype(str)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.bar(etiquetas, df_sorted['RMSE'])\n",
    "\n",
    "    # A√±adir los valores de RMSE sobre cada barra\n",
    "    for bar, rmse in zip(bars, df_sorted['RMSE']):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                 f'{rmse:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer resultados de los modelos evaluados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sin escalar\n",
    "df_ns_7 = pd.read_csv('./progreso/reg_resultados_T7.csv')\n",
    "df_ns_14 = pd.read_csv('./progreso/reg_resultados_T14.csv')\n",
    "df_ns_21 = pd.read_csv('./progreso/reg_resultados_T21.csv')\n",
    "\n",
    "##Escalados\n",
    "df_s_7 = pd.read_csv('./progreso/s_resultados_T7.csv')\n",
    "df_s_14 = pd.read_csv('./progreso/s_resultados_T14.csv')\n",
    "df_s_21 = pd.read_csv('./progreso/s_resultados_T21.csv')\n",
    "\n",
    "## MLP\n",
    "df_mlp_7 = pd.read_csv('./progreso/mlp_resultados_T7.csv')\n",
    "df_mlp_14 = pd.read_csv('./progreso/mlp_resultados_T14.csv')\n",
    "df_mlp_21 = pd.read_csv('./progreso/mlp_resultados_T21.csv')\n",
    "\n",
    "## LSTM\n",
    "df_lstm_7 = pd.read_csv('./progreso/LSTM_resultados_T7.csv')\n",
    "df_lstm_14 = pd.read_csv('./progreso/LSTM_resultados_T14.csv')\n",
    "df_lstm_21 = pd.read_csv('./progreso/LSTM_resultados_T21.csv')\n",
    "\n",
    "## RNN\n",
    "df_rnn_7 = pd.read_csv('./progreso/RNN_resultados_T7.csv')\n",
    "df_rnn_14 = pd.read_csv('./progreso/RNN_resultados_T14.csv')\n",
    "df_rnn_21 = pd.read_csv('./progreso/RNN_resultados_T21.csv')\n",
    "\n",
    "\n",
    "#Concatenar\n",
    "df_w_7 = pd.concat([df_ns_7, df_s_7, df_mlp_7, df_lstm_7, df_rnn_7])\n",
    "df_w_14 = pd.concat([df_ns_14, df_s_14, df_mlp_14, df_lstm_14,df_rnn_14 ])\n",
    "df_w_21 = pd.concat([df_ns_21, df_s_21,df_mlp_21, df_lstm_21, df_rnn_21])\n",
    "\n",
    "#Concatenado todos\n",
    "df_total = pd.concat([df_w_7, df_w_14, df_w_21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_bar(df_w_7.sort_values('RMSE', ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la grafica superior, observamos el top 5 de modelos para la ventana de 7 d√≠as, para dicha ventada el ramdon forest de 100 estimadores y m√°xima profundad de 5 obtiene el menor RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_bar(df_w_14.sort_values('RMSE', ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la grafica superior, observamos el top 5 de modelos para la ventana de 14 d√≠as, para dicha ventada el XGB de 100 estimadores y t√°sa de aprendizaje de 0.01 obtiene el menor RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_bar(df_w_21.sort_values('RMSE', ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la grafica superior, observamos el top 5 de modelos para la ventana de 21 d√≠as, para dicha ventada el ramdon forest de 100 estimadores y m√°xima profundad de 5 obtiene el menor RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.sort_values(by= 'RMSE', ascending= True).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
