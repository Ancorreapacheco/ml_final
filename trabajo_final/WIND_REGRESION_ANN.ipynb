{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ignorar advertencias ===\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Manejo del sistema y utilidades ===\n",
    "import os\n",
    "import ast\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Manipulación de datos ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Visualización ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Preprocesamiento y métricas ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "# === Diagnóstico estadístico ===\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# === Redes neuronales (Keras / TensorFlow) ===\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow está utilizando la GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Listar dispositivos disponibles\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if devices:\n",
    "    print(f\"TensorFlow está utilizando la GPU: {devices}\")\n",
    "else:\n",
    "    print(\"TensorFlow no está utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA (UTC)</th>\n",
       "      <th>VENTO, DIREï¿½ï¿½O HORARIA (gr) (ï¿½ (gr))</th>\n",
       "      <th>VENTO, VELOCIDADE HORARIA (m/s)</th>\n",
       "      <th>UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>TEMPERATURA Mï¿½XIMA NA HORA ANT. (AUT) (ï¿½C)</th>\n",
       "      <th>TEMPERATURA Mï¿½NIMA NA HORA ANT. (AUT) (ï¿½C)</th>\n",
       "      <th>UMIDADE RELATIVA DO AR, HORARIA (%)</th>\n",
       "      <th>PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)</th>\n",
       "      <th>PRECIPITAï¿½ï¿½O TOTAL, HORï¿½RIO (mm)</th>\n",
       "      <th>VENTO, RAJADA MAXIMA (m/s)</th>\n",
       "      <th>PRESSï¿½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)</th>\n",
       "      <th>PRESSï¿½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HORA (UTC)  VENTO, DIREï¿½ï¿½O HORARIA (gr) (ï¿½ (gr))  \\\n",
       "0      12:00                                    0.809017   \n",
       "\n",
       "   VENTO, VELOCIDADE HORARIA (m/s)  UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)  \\\n",
       "0                              1.8                                      69.0   \n",
       "\n",
       "   UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)  \\\n",
       "0                                      60.0   \n",
       "\n",
       "   TEMPERATURA Mï¿½XIMA NA HORA ANT. (AUT) (ï¿½C)  \\\n",
       "0                                            22.6   \n",
       "\n",
       "   TEMPERATURA Mï¿½NIMA NA HORA ANT. (AUT) (ï¿½C)  \\\n",
       "0                                            20.7   \n",
       "\n",
       "   UMIDADE RELATIVA DO AR, HORARIA (%)  \\\n",
       "0                                 61.0   \n",
       "\n",
       "   PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)  \\\n",
       "0                                              888.2       \n",
       "\n",
       "   PRECIPITAï¿½ï¿½O TOTAL, HORï¿½RIO (mm)  VENTO, RAJADA MAXIMA (m/s)  \\\n",
       "0                                     0.0                         3.8   \n",
       "\n",
       "   PRESSï¿½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)  \\\n",
       "0                                              888.2   \n",
       "\n",
       "   PRESSï¿½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)  \n",
       "0                                              887.7   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA</th>\n",
       "      <th>WIND_DIR_HOR</th>\n",
       "      <th>WIND_VEL_HOR</th>\n",
       "      <th>HUM_REL_MAX_ANT</th>\n",
       "      <th>HUM_REL_MIN_ANT</th>\n",
       "      <th>TEMP_MAX_ANT</th>\n",
       "      <th>TEMP_MIN_ANT</th>\n",
       "      <th>HUM_REL_HOR</th>\n",
       "      <th>PRES_ATM_NIV</th>\n",
       "      <th>PREC_HOR</th>\n",
       "      <th>RAFAGA_VIENTO</th>\n",
       "      <th>PRES_ATM_MAX_ANT</th>\n",
       "      <th>PRES_ATM_MIN_ANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13:00</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>888.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>888.4</td>\n",
       "      <td>888.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HORA  WIND_DIR_HOR  WIND_VEL_HOR  HUM_REL_MAX_ANT  HUM_REL_MIN_ANT  \\\n",
       "0  12:00      0.809017           1.8             69.0             60.0   \n",
       "1  13:00      0.965926           2.7             62.0             55.0   \n",
       "\n",
       "   TEMP_MAX_ANT  TEMP_MIN_ANT  HUM_REL_HOR  PRES_ATM_NIV  PREC_HOR  \\\n",
       "0          22.6          20.7         61.0         888.2       0.0   \n",
       "1          24.2          22.5         55.0         888.4       0.0   \n",
       "\n",
       "   RAFAGA_VIENTO  PRES_ATM_MAX_ANT  PRES_ATM_MIN_ANT  \n",
       "0            3.8             888.2             887.7  \n",
       "1            4.7             888.4             888.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87693 entries, 0 to 87692\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   HORA              87693 non-null  object \n",
      " 1   WIND_DIR_HOR      87693 non-null  float64\n",
      " 2   WIND_VEL_HOR      87693 non-null  float64\n",
      " 3   HUM_REL_MAX_ANT   87693 non-null  float64\n",
      " 4   HUM_REL_MIN_ANT   87693 non-null  float64\n",
      " 5   TEMP_MAX_ANT      87693 non-null  float64\n",
      " 6   TEMP_MIN_ANT      87693 non-null  float64\n",
      " 7   HUM_REL_HOR       87693 non-null  float64\n",
      " 8   PRES_ATM_NIV      87693 non-null  float64\n",
      " 9   PREC_HOR          87693 non-null  float64\n",
      " 10  RAFAGA_VIENTO     87693 non-null  float64\n",
      " 11  PRES_ATM_MAX_ANT  87693 non-null  float64\n",
      " 12  PRES_ATM_MIN_ANT  87693 non-null  float64\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORA                0\n",
       "WIND_DIR_HOR        0\n",
       "WIND_VEL_HOR        0\n",
       "HUM_REL_MAX_ANT     0\n",
       "HUM_REL_MIN_ANT     0\n",
       "TEMP_MAX_ANT        0\n",
       "TEMP_MIN_ANT        0\n",
       "HUM_REL_HOR         0\n",
       "PRES_ATM_NIV        0\n",
       "PREC_HOR            0\n",
       "RAFAGA_VIENTO       0\n",
       "PRES_ATM_MAX_ANT    0\n",
       "PRES_ATM_MIN_ANT    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos con escalamiento de variables\n",
    "\n",
    "Los siguientes modelos requieren escalamiento de las variables predictoras, por lo que se trabajan en la misma función\n",
    "\n",
    "* KNeighboors (vecinos mas cercanos)\n",
    "* Maquinas de soporte vectoriales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias para el manejo de archivos, arrays, dataframes,\n",
    "# métricas y construcción de modelos de redes neuronales.\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error,\n",
    "    mean_absolute_percentage_error, r2_score\n",
    ")\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Construye un modelo Multilayer Perceptron (MLP) para regresión\n",
    "\n",
    "def build_mlp_model(input_dim, hidden_layers, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Construye un modelo RNN simple con una sola capa recurrente\n",
    "\n",
    "def build_rnn_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Construye un modelo LSTM para capturar relaciones temporales largas\n",
    "\n",
    "def build_lstm_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Genera secuencias de datos para modelos RNN o LSTM\n",
    "\n",
    "def create_rnn_sequences(df, target_col, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        seq = df.iloc[i:i+window_size]\n",
    "        X.append(seq.drop(columns=[target_col]).values)\n",
    "        y.append(df.iloc[i+window_size][target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Función principal para entrenamiento y evaluación de MLP, RNN y LSTM con sliding windows\n",
    "\n",
    "def sliding_window_regression_models_scaling_keras_rnn(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14],\n",
    "    test_window=1,\n",
    "    model_types=['MLP', 'RNN', 'LSTM'],\n",
    "    mlp_params={\n",
    "        'hidden_layers': [[16], [32], [64]],\n",
    "        'activation': ['relu'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    rnn_params={\n",
    "        'hidden_units': [16, 32],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    lstm_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso_keras_rnn'\n",
    "):\n",
    "    # Crea carpeta de resultados si no existe\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    # Itera sobre diferentes ventanas de entrenamiento T\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\", unit=\"ventana\"):\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - T_hours - test_hours + 1\n",
    "        output_path = os.path.join(save_path, f'ANN_resultados_T{T}.csv')\n",
    "\n",
    "        # Carga resultados previos si existen para evitar cálculos redundantes\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # Itera sobre MLP, RNN o LSTM\n",
    "        for model_type in model_types:\n",
    "            if model_type == 'MLP':\n",
    "                param_grid = list(product(*mlp_params.values()))\n",
    "                param_keys = list(mlp_params.keys())\n",
    "            elif model_type == 'RNN':\n",
    "                param_grid = list(product(*rnn_params.values()))\n",
    "                param_keys = list(rnn_params.keys())\n",
    "            elif model_type == 'LSTM':\n",
    "                param_grid = list(product(*lstm_params.values()))\n",
    "                param_keys = list(lstm_params.keys())\n",
    "\n",
    "            # Itera sobre combinaciones de hiperparámetros\n",
    "            for combo in param_grid:\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                print(f\"🔧 Evaluando modelo {model_type} con hiperparámetros: {param_dict}\")\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                if not df_prev.empty and (df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict)).any():\n",
    "                    continue\n",
    "\n",
    "                resultados = {k: [] for k in ['MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p']}\n",
    "\n",
    "                # Sliding window sobre el conjunto de datos\n",
    "                for start in range(0, total_windows, 24):\n",
    "                    if model_type == 'MLP':\n",
    "                        train = df.iloc[start: start + T_hours]\n",
    "                        test = df.iloc[start + T_hours: start + T_hours + test_hours]\n",
    "\n",
    "                        X_train = train.drop(columns=[target_col])\n",
    "                        y_train = train[target_col]\n",
    "                        X_test = test.drop(columns=[target_col])\n",
    "                        y_test = test[target_col]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train = scaler.fit_transform(X_train)\n",
    "                        X_test = scaler.transform(X_test)\n",
    "\n",
    "                        model = build_mlp_model(\n",
    "                            input_dim=X_train.shape[1],\n",
    "                            hidden_layers=param_dict['hidden_layers'],\n",
    "                            activation=param_dict['activation'],\n",
    "                            learning_rate=param_dict['learning_rate']\n",
    "                        )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    else:\n",
    "                        # Escalamiento sin data leakage para RNN/LSTM\n",
    "                        data_window = df.iloc[start: start + T_hours + test_hours].copy()\n",
    "                        train_data = data_window.iloc[:T_hours]\n",
    "                        test_data = data_window.iloc[T_hours:]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_scaled = scaler.fit_transform(train_data.drop(columns=[target_col]))\n",
    "                        X_test_scaled = scaler.transform(test_data.drop(columns=[target_col]))\n",
    "\n",
    "                        train_scaled = pd.DataFrame(X_train_scaled, columns=train_data.columns.drop(target_col))\n",
    "                        train_scaled[target_col] = train_data[target_col].values\n",
    "\n",
    "                        test_scaled = pd.DataFrame(X_test_scaled, columns=test_data.columns.drop(target_col))\n",
    "                        test_scaled[target_col] = test_data[target_col].values\n",
    "\n",
    "                        scaled = pd.concat([train_scaled, test_scaled])\n",
    "                        X, y = create_rnn_sequences(scaled, target_col, T_hours)\n",
    "                        X_train, y_train = X[:-1], y[:-1]\n",
    "                        X_test, y_test = X[-1:], y[-1:]\n",
    "\n",
    "                        if model_type == 'RNN':\n",
    "                            model = build_rnn_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "                        else:  # LSTM\n",
    "                            model = build_lstm_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    # Cálculo de métricas\n",
    "                    residuals = y_test.values - y_pred if hasattr(y_test, 'values') else y_test - y_pred\n",
    "                    resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                    resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                    resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                    resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                    resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "                    if model_type == 'MLP' and len(residuals) >= 2:\n",
    "                        ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                    else:\n",
    "                        ljung_p = np.nan\n",
    "                    resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "                # Registro y guardado de resultados por combinación\n",
    "                nuevo_row = pd.DataFrame([{\n",
    "                    'modelo': model_type,\n",
    "                    'params': param_dict,\n",
    "                    'T_dias': T,\n",
    "                    'T_horas': T_hours,\n",
    "                    'MAPE': np.mean(resultados['MAPE']),\n",
    "                    'MAE': np.mean(resultados['MAE']),\n",
    "                    'RMSE': np.mean(resultados['RMSE']),\n",
    "                    'MSE': np.mean(resultados['MSE']),\n",
    "                    'R2': np.mean(resultados['R2']),\n",
    "                    'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "                }])\n",
    "                df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "                print(f\"✅ Finalizado {model_type} con RMSE promedio: {np.mean(resultados['RMSE']):.4f}\")\n",
    "                df_prev.to_csv(output_path, index=False)\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando ventanas T:   0%|          | 0/2 [00:00<?, ?ventana/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Evaluando modelo MLP con hiperparámetros: {'hidden_layers': [16], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 50, 'batch_size': 32}\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029BF1ACE4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029BCEB5CC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "resultados_por_T = sliding_window_regression_models_scaling_keras_rnn(df, target_col='WIND_VEL_HOR')\n",
    "\n",
    "# Ver los DataFrames en memoria\n",
    "df_w_7 = resultados_por_T[7]    # Para T=7 días\n",
    "df_w_14 = resultados_por_T[14]    # Para T=7 días\n",
    "df_w_21 = resultados_por_T[21]    # Para T=7 días\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por RMSE de mayor a menor\n",
    "df_w_7_sorted = df_w_7.sort_values(by=\"RMSE\", ascending=True)\n",
    "\n",
    "# Etiquetas combinadas modelo + params\n",
    "etiquetas = df_w_7_sorted['modelo'].astype(str) + ' ' + df_w_7_sorted['params'].astype(str)\n",
    "\n",
    "# Crear la gráfica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(etiquetas, df_w_7_sorted['RMSE'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE por Modelo - T=7 días (ordenado de mayor a menor)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighboors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que normalizar datos por eso se hace por aparte\n",
    "\n",
    "En principio, hay dos parámetros importantes en el clasificador KNeighbors: el número de vecinos y cómo se mide la distancia entre los puntos de datos. En la práctica, utilizar un número pequeño de vecinos, como tres o cinco, suele funcionar bien, pero se debería ajustar este parámetro.\n",
    "\n",
    "La elección de la medida de distancia correcta es también crucial. Por defecto, KNeighbors utiliza la distancia euclidiana, que funciona bien en muchos casos. Uno de los puntos fuertes de \n",
    "-NN es que el modelo es muy fácil de entender, y a menudo da un rendimiento razonable sin necesidad de muchos ajustes. El uso de este algoritmo es un buen método de referencia para probar, antes de considerar técnicas más avanzadas.\n",
    "\n",
    "La construcción del modelo de vecinos más cercanos suele ser muy rápida, pero cuando el conjunto de entrenamiento es muy grande (ya sea en número de características o en número de muestras) la predicción puede ser lenta. Cuando se utiliza el algoritmo \n",
    "-NN, es importante pre-procesar los datos, tema que revisaremos en secciones posteriores. Este enfoque no suele funcionar bien en conjuntos de datos con muchas características (cientos o más), y lo hace especialmente mal con conjuntos de datos en los que la mayoría de las características son 0 la mayor parte del tiempo (los llamados conjuntos de datos dispersos).\n",
    "\n",
    "Por lo tanto, aunque el algoritmo de \n",
    "-vecinos más cercanos es fácil de entender, no se utiliza a menudo en la práctica, debido a que la predicción es lenta y a su incapacidad para manejar muchas características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dudas para el profesor\n",
    "\n",
    "1. El fit del escalador se debe realizar con los datos de train, y con ese trabajar tanto train como test? Como se hace en producción??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
