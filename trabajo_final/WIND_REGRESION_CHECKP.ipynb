{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos sin escalamiento de variables\n",
    "\n",
    "Los siguientes modelos no requieren escalamiento de las variables, por lo que se trabajan en la misma funci√≥n\n",
    "\n",
    "* Regresi√≥n l√≠neal\n",
    "* Regresi√≥n Ridge\n",
    "* Regresi√≥n Lasso\n",
    "* Arboles de regresi√≥n\n",
    "* Arboles aleatorios de regresi√≥n\n",
    "* XGBoost Regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1,0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1,0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15,30,50,100], 'min_samples_leaf':[1,3,5,10,15,20] }},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': None},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100, 300, 500], 'max_depth': [5, 10, 15,30], 'n_jobs': [-1] }},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state':[0], 'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3], 'n_estimators':[100,300,500]}},\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\", unit=\"ventana\"):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - T_hours - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'resultados_T{T}.csv')\n",
    "\n",
    "        # Cargar resultados previos\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # Precalcular splits\n",
    "        splits = []\n",
    "        for start in range(0,total_windows,24): #Para que la ventana se mueva cada 24 horas\n",
    "            train = df.iloc[start: start + T_hours]\n",
    "            test = df.iloc[start + T_hours: start + T_hours + test_hours]\n",
    "\n",
    "            X_train = train.drop(columns=[target_col])\n",
    "            y_train = train[target_col]\n",
    "            X_test = test.drop(columns=[target_col])\n",
    "            y_test = test[target_col]\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # Crear todos los modelos con combinaciones completas de par√°metros\n",
    "        models = []\n",
    "        for modelo in modelos:\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': None})\n",
    "            else:\n",
    "                keys = list(param_grid.keys())\n",
    "                values = list(param_grid.values())\n",
    "                for combo in product(*values):\n",
    "                    param_dict = dict(zip(keys, combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # Evaluar cada modelo\n",
    "        for m in models:\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) & \n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"‚úì Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=False):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test.values - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            #print(f\"üò∂‚Äçüå´Ô∏èNumero de modelos realizado {len(resultados['MAPE'])}\")\n",
    "            # Guardar inmediatamente el resultado de este modelo\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_por_T = sliding_window_regression_models(df, target_col='WIND_VEL_HOR')\n",
    "\n",
    "# Ver los DataFrames en memoria\n",
    "df_w_7 = resultados_por_T[7]    # Para T=7 d√≠as\n",
    "df_w_14 = resultados_por_T[14]    # Para T=7 d√≠as\n",
    "df_w_21 = resultados_por_T[21]    # Para T=7 d√≠as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_rmse_bar(df, title='RMSE por Modelo', sort_ascending=True, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Genera una gr√°fica de barras del RMSE por modelo, ordenada seg√∫n el valor del RMSE.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame que debe contener las columnas 'modelo', 'params' y 'RMSE'.\n",
    "    - title: T√≠tulo de la gr√°fica.\n",
    "    - sort_ascending: Booleano, si True ordena de menor a mayor RMSE.\n",
    "    - figsize: Tama√±o de la figura (tupla).\n",
    "\n",
    "    Retorna:\n",
    "    - None (muestra la gr√°fica).\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(by=\"RMSE\", ascending=sort_ascending)\n",
    "    etiquetas = df_sorted['modelo'].astype(str) + ' ' + df_sorted['params'].astype(str)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(etiquetas, df_sorted['RMSE'])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_bar(df_w_7, title='RMSE por Modelo - T=7 d√≠as (ordenado de menor a mayor)', sort_ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por RMSE de mayor a menor\n",
    "df_w_7_sorted = df_w_7.sort_values(by=\"RMSE\", ascending=True)\n",
    "\n",
    "# Etiquetas combinadas modelo + params\n",
    "etiquetas = df_w_7_sorted['modelo'].astype(str) + ' ' + df_w_7_sorted['params'].astype(str)\n",
    "\n",
    "# Crear la gr√°fica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(etiquetas, df_w_7_sorted['RMSE'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE por Modelo - T=7 d√≠as (ordenado de mayor a menor)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aseg√∫rate de haber ejecutado esto antes:\n",
    "# resultados_por_T = sliding_window_regression_models(df, target_col='WIND_VEL_HOR')\n",
    "# df_w_7 = resultados_por_T[7]\n",
    "\n",
    "# Ordenar por RMSE de mayor a menor\n",
    "df_w_14_sorted = df_w_14.sort_values(by=\"RMSE\", ascending=True)\n",
    "\n",
    "# Etiquetas combinadas modelo + params\n",
    "etiquetas = df_w_14_sorted['modelo'].astype(str) + ' ' + df_w_14_sorted['params'].astype(str)\n",
    "\n",
    "# Crear la gr√°fica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(etiquetas, df_w_14_sorted['RMSE'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE por Modelo - T=14 d√≠as (ordenado de mayor a menor)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aseg√∫rate de haber ejecutado esto antes:\n",
    "# resultados_por_T = sliding_window_regression_models(df, target_col='WIND_VEL_HOR')\n",
    "# df_w_7 = resultados_por_T[7]\n",
    "\n",
    "# Ordenar por RMSE de mayor a menor\n",
    "df_w_21_sorted = df_w_21.sort_values(by=\"RMSE\", ascending=True)\n",
    "\n",
    "# Etiquetas combinadas modelo + params\n",
    "etiquetas = df_w_21_sorted['modelo'].astype(str) + ' ' + df_w_21_sorted['params'].astype(str)\n",
    "\n",
    "# Crear la gr√°fica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(etiquetas, df_w_21_sorted['RMSE'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE por Modelo - T=21 d√≠as (ordenado de mayor a menor)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos con escalamiento de variables\n",
    "\n",
    "Los siguientes modelos requieren escalamiento de las variables predictoras, por lo que se trabajan en la misma funci√≥n\n",
    "\n",
    "* KNeighboors (vecinos mas cercanos)\n",
    "* Maquinas de soporte vectoriales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_scaling(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'Kneighboors', 'ModelClass': KNeighborsRegressor, 'params': {'n_neighbors': [5, 10,15], 'algorithm': ['ball_tree', 'kd_tree'], 'leaf_size':[30,60], 'n_jobs':[-1], 'weights': ['uniform', 'distance']}},\n",
    "        {'name': 'SVR', 'ModelClass': SVR, 'params': {\n",
    "          'C': [0.1, 1.0, 10],            # Regularizaci√≥n (m√°s alto = menos tolerancia al error)\n",
    "          'epsilon': [0.01, 0.1, 0.2],     # Margen de tolerancia al error sin penalizaci√≥n\n",
    "          'kernel': ['rbf','linear'],          # Funci√≥n de kernel (RBF = radial basis function, muy usada)\n",
    "          'n_jobs':[-1]\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\", unit=\"ventana\"):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - T_hours - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'resultados_T{T}.csv')\n",
    "\n",
    "        # Cargar resultados previos\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # Precalcular splits\n",
    "        splits = []\n",
    "        for start in range(0,total_windows,24): #Para que la ventana se mueva cada 24 horas\n",
    "            train = df.iloc[start: start + T_hours]\n",
    "            test = df.iloc[start + T_hours: start + T_hours + test_hours]\n",
    "\n",
    "            X_train = train.drop(columns=[target_col])\n",
    "            y_train = train[target_col]\n",
    "            X_test = test.drop(columns=[target_col])\n",
    "            y_test = test[target_col]\n",
    "\n",
    "            #Escalo variables\n",
    "                #Instancio el escalador\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # Crear todos los modelos con combinaciones completas de par√°metros\n",
    "        models = []\n",
    "        for modelo in modelos:\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': None})\n",
    "            else:\n",
    "                keys = list(param_grid.keys())\n",
    "                values = list(param_grid.values())\n",
    "                for combo in product(*values):\n",
    "                    param_dict = dict(zip(keys, combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # Evaluar cada modelo\n",
    "        for m in models:\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) & \n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"‚úì Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=False):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test.values - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            #print(f\"üò∂‚Äçüå´Ô∏èNumero de modelos realizado {len(resultados['MAPE'])}\")\n",
    "            # Guardar inmediatamente el resultado de este modelo\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighboors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que normalizar datos por eso se hace por aparte\n",
    "\n",
    "En principio, hay dos par√°metros importantes en el clasificador KNeighbors: el n√∫mero de vecinos y c√≥mo se mide la distancia entre los puntos de datos. En la pr√°ctica, utilizar un n√∫mero peque√±o de vecinos, como tres o cinco, suele funcionar bien, pero se deber√≠a ajustar este par√°metro.\n",
    "\n",
    "La elecci√≥n de la medida de distancia correcta es tambi√©n crucial. Por defecto, KNeighbors utiliza la distancia euclidiana, que funciona bien en muchos casos. Uno de los puntos fuertes de \n",
    "-NN es que el modelo es muy f√°cil de entender, y a menudo da un rendimiento razonable sin necesidad de muchos ajustes. El uso de este algoritmo es un buen m√©todo de referencia para probar, antes de considerar t√©cnicas m√°s avanzadas.\n",
    "\n",
    "La construcci√≥n del modelo de vecinos m√°s cercanos suele ser muy r√°pida, pero cuando el conjunto de entrenamiento es muy grande (ya sea en n√∫mero de caracter√≠sticas o en n√∫mero de muestras) la predicci√≥n puede ser lenta. Cuando se utiliza el algoritmo \n",
    "-NN, es importante pre-procesar los datos, tema que revisaremos en secciones posteriores. Este enfoque no suele funcionar bien en conjuntos de datos con muchas caracter√≠sticas (cientos o m√°s), y lo hace especialmente mal con conjuntos de datos en los que la mayor√≠a de las caracter√≠sticas son 0 la mayor parte del tiempo (los llamados conjuntos de datos dispersos).\n",
    "\n",
    "Por lo tanto, aunque el algoritmo de \n",
    "-vecinos m√°s cercanos es f√°cil de entender, no se utiliza a menudo en la pr√°ctica, debido a que la predicci√≥n es lenta y a su incapacidad para manejar muchas caracter√≠sticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dudas para el profesor\n",
    "\n",
    "1. El fit del escalador se debe realizar con los datos de train, y con ese trabajar tanto train como test? Como se hace en producci√≥n??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
