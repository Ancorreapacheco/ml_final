{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_lagged_features(\n",
    "    df: pd.DataFrame,\n",
    "    response_col: str,\n",
    "    num_lags: int,\n",
    "    response_shift: int = 0,\n",
    "    output_path: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con caracter√≠sticas de retardo (lag features) para modelado,\n",
    "    y opcionalmente lo exporta a un archivo Excel, permitiendo desplazar la variable de respuesta.\n",
    "\n",
    "    Par√°metros:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original que contiene las columnas de respuesta y predictoras.\n",
    "        El √≠ndice debe estar ordenado temporalmente.\n",
    "\n",
    "    response_col : str\n",
    "        Nombre de la columna que se utilizar√° como variable de respuesta.\n",
    "\n",
    "    num_lags : int\n",
    "        N√∫mero de per√≠odos de retardo a considerar para las caracter√≠sticas.\n",
    "\n",
    "    response_shift : int, opcional (por defecto 0)\n",
    "        N√∫mero de per√≠odos para desplazar la variable de respuesta.\n",
    "        - Si es positivo, desplaza la respuesta hacia el futuro (predice el futuro).\n",
    "        - Si es negativo, desplaza la respuesta hacia el pasado.\n",
    "        - Si es 0, no se desplaza la respuesta.\n",
    "\n",
    "    output_path : str, opcional (por defecto None)\n",
    "        Ruta completa donde se exportar√° el DataFrame resultante en formato Excel.\n",
    "        Si es None, no se exportar√° el archivo.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las caracter√≠sticas de retardo y la variable de respuesta.\n",
    "        Las filas con valores faltantes ser√°n eliminadas.\n",
    "    \"\"\"\n",
    "\n",
    "    if response_col not in df.columns:\n",
    "        raise ValueError(f\"La columna de respuesta '{response_col}' no est√° en el DataFrame.\")\n",
    "\n",
    "    # Determinar autom√°ticamente las columnas predictoras\n",
    "    predictor_cols = df.columns.drop(response_col)\n",
    "\n",
    "    # Crear DataFrame para caracter√≠sticas de retardo\n",
    "    lag_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in predictor_cols:\n",
    "        for lag in range(1, num_lags + 1):\n",
    "            lag_features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    final_df = lag_features.copy()\n",
    "\n",
    "    # Agregar variable de respuesta desplazada\n",
    "    if response_shift != 0:\n",
    "        final_df[response_col] = df[response_col].shift(-response_shift + 1)\n",
    "    else:\n",
    "        final_df[response_col] = df[response_col]\n",
    "\n",
    "    # Eliminar valores faltantes y resetear √≠ndice\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Exportar si se especifica una ruta\n",
    "    if output_path:\n",
    "        try:\n",
    "            directory = os.path.dirname(output_path)\n",
    "            if directory:\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "            final_df.to_excel(output_path, index=False)\n",
    "            print(f\"El DataFrame con caracter√≠sticas de retardo ha sido exportado exitosamente a: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al exportar el DataFrame a Excel: {e}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'Kneighboors', 'ModelClass': KNeighborsRegressor, 'params': {'n_neighbors': [5, 10,15], 'algorithm': ['ball_tree', 'kd_tree'], 'leaf_size':[30,60], 'n_jobs':[-1], 'weights': ['uniform', 'distance']}},\n",
    "        {'name': 'SVR', 'ModelClass': SVR, 'params': {\n",
    "          'C': [0.1, 1.0, 10],            # Regularizaci√≥n (m√°s alto = menos tolerancia al error)\n",
    "          'epsilon': [0.01, 0.1, 0.2],     # Margen de tolerancia al error sin penalizaci√≥n\n",
    "          'kernel': ['rbf','linear'],          # Funci√≥n de kernel (RBF = radial basis function, muy usada)\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nüß™ Ventana T = {T} d√≠as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'üòé Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f's_resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # ‚ö° Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # üß† Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # üîç Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"‚úì Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                #Escalo variables\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.fit_transform(X_test)\n",
    "                \n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"üì¶ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"‚úî Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'Kneighboors', 'ModelClass': KNeighborsRegressor, 'params': {'n_neighbors': [5, 10,15], 'algorithm': ['ball_tree', 'kd_tree'], 'leaf_size':[30,60], 'n_jobs':[-1], 'weights': ['uniform', 'distance']}},\n",
    "        {'name': 'SVR', 'ModelClass': SVR, 'params': {\n",
    "          'C': [0.1, 1.0, 10],            # Regularizaci√≥n (m√°s alto = menos tolerancia al error)\n",
    "          'epsilon': [0.01, 0.1, 0.2],     # Margen de tolerancia al error sin penalizaci√≥n\n",
    "          'kernel': ['rbf','linear'],          # Funci√≥n de kernel (RBF = radial basis function, muy usada)\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
