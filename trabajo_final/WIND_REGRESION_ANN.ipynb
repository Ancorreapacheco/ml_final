{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ignorar advertencias ===\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Manejo del sistema y utilidades ===\n",
    "import os\n",
    "import ast\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === ManipulaciÃ³n de datos ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === VisualizaciÃ³n ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Preprocesamiento y mÃ©tricas ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "# === DiagnÃ³stico estadÃ­stico ===\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# === Redes neuronales (Keras / TensorFlow) ===\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow estÃ¡ utilizando la GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Listar dispositivos disponibles\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if devices:\n",
    "    print(f\"TensorFlow estÃ¡ utilizando la GPU: {devices}\")\n",
    "else:\n",
    "    print(\"TensorFlow no estÃ¡ utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegresiÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA (UTC)</th>\n",
       "      <th>VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))</th>\n",
       "      <th>VENTO, VELOCIDADE HORARIA (m/s)</th>\n",
       "      <th>UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>UMIDADE RELATIVA DO AR, HORARIA (%)</th>\n",
       "      <th>PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)</th>\n",
       "      <th>PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)</th>\n",
       "      <th>VENTO, RAJADA MAXIMA (m/s)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HORA (UTC)  VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))  \\\n",
       "0      12:00                                    0.809017   \n",
       "\n",
       "   VENTO, VELOCIDADE HORARIA (m/s)  UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)  \\\n",
       "0                              1.8                                      69.0   \n",
       "\n",
       "   UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)  \\\n",
       "0                                      60.0   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            22.6   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            20.7   \n",
       "\n",
       "   UMIDADE RELATIVA DO AR, HORARIA (%)  \\\n",
       "0                                 61.0   \n",
       "\n",
       "   PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)  \\\n",
       "0                                              888.2       \n",
       "\n",
       "   PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)  VENTO, RAJADA MAXIMA (m/s)  \\\n",
       "0                                     0.0                         3.8   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)  \\\n",
       "0                                              888.2   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)  \n",
       "0                                              887.7   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA</th>\n",
       "      <th>WIND_DIR_HOR</th>\n",
       "      <th>WIND_VEL_HOR</th>\n",
       "      <th>HUM_REL_MAX_ANT</th>\n",
       "      <th>HUM_REL_MIN_ANT</th>\n",
       "      <th>TEMP_MAX_ANT</th>\n",
       "      <th>TEMP_MIN_ANT</th>\n",
       "      <th>HUM_REL_HOR</th>\n",
       "      <th>PRES_ATM_NIV</th>\n",
       "      <th>PREC_HOR</th>\n",
       "      <th>RAFAGA_VIENTO</th>\n",
       "      <th>PRES_ATM_MAX_ANT</th>\n",
       "      <th>PRES_ATM_MIN_ANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13:00</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>888.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>888.4</td>\n",
       "      <td>888.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HORA  WIND_DIR_HOR  WIND_VEL_HOR  HUM_REL_MAX_ANT  HUM_REL_MIN_ANT  \\\n",
       "0  12:00      0.809017           1.8             69.0             60.0   \n",
       "1  13:00      0.965926           2.7             62.0             55.0   \n",
       "\n",
       "   TEMP_MAX_ANT  TEMP_MIN_ANT  HUM_REL_HOR  PRES_ATM_NIV  PREC_HOR  \\\n",
       "0          22.6          20.7         61.0         888.2       0.0   \n",
       "1          24.2          22.5         55.0         888.4       0.0   \n",
       "\n",
       "   RAFAGA_VIENTO  PRES_ATM_MAX_ANT  PRES_ATM_MIN_ANT  \n",
       "0            3.8             888.2             887.7  \n",
       "1            4.7             888.4             888.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87693 entries, 0 to 87692\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   HORA              87693 non-null  object \n",
      " 1   WIND_DIR_HOR      87693 non-null  float64\n",
      " 2   WIND_VEL_HOR      87693 non-null  float64\n",
      " 3   HUM_REL_MAX_ANT   87693 non-null  float64\n",
      " 4   HUM_REL_MIN_ANT   87693 non-null  float64\n",
      " 5   TEMP_MAX_ANT      87693 non-null  float64\n",
      " 6   TEMP_MIN_ANT      87693 non-null  float64\n",
      " 7   HUM_REL_HOR       87693 non-null  float64\n",
      " 8   PRES_ATM_NIV      87693 non-null  float64\n",
      " 9   PREC_HOR          87693 non-null  float64\n",
      " 10  RAFAGA_VIENTO     87693 non-null  float64\n",
      " 11  PRES_ATM_MAX_ANT  87693 non-null  float64\n",
      " 12  PRES_ATM_MIN_ANT  87693 non-null  float64\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORA                0\n",
       "WIND_DIR_HOR        0\n",
       "WIND_VEL_HOR        0\n",
       "HUM_REL_MAX_ANT     0\n",
       "HUM_REL_MIN_ANT     0\n",
       "TEMP_MAX_ANT        0\n",
       "TEMP_MIN_ANT        0\n",
       "HUM_REL_HOR         0\n",
       "PRES_ATM_NIV        0\n",
       "PREC_HOR            0\n",
       "RAFAGA_VIENTO       0\n",
       "PRES_ATM_MAX_ANT    0\n",
       "PRES_ATM_MIN_ANT    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos con escalamiento de variables\n",
    "\n",
    "Los siguientes modelos requieren escalamiento de las variables predictoras, por lo que se trabajan en la misma funciÃ³n\n",
    "\n",
    "* KNeighboors (vecinos mas cercanos)\n",
    "* Maquinas de soporte vectoriales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportaciÃ³n de librerÃ­as necesarias para el manejo de archivos, arrays, dataframes,\n",
    "# mÃ©tricas y construcciÃ³n de modelos de redes neuronales.\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error,\n",
    "    mean_absolute_percentage_error, r2_score\n",
    ")\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Construye un modelo Multilayer Perceptron (MLP) para regresiÃ³n\n",
    "\n",
    "def build_mlp_model(input_dim, hidden_layers, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Construye un modelo RNN simple con una sola capa recurrente\n",
    "\n",
    "def build_rnn_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Construye un modelo LSTM para capturar relaciones temporales largas\n",
    "\n",
    "def build_lstm_model(timesteps, input_dim, hidden_units, activation='tanh', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, activation=activation, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Genera secuencias de datos para modelos RNN o LSTM\n",
    "\n",
    "def create_rnn_sequences(df, target_col, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        seq = df.iloc[i:i+window_size]\n",
    "        X.append(seq.drop(columns=[target_col]).values)\n",
    "        y.append(df.iloc[i+window_size][target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# FunciÃ³n principal para entrenamiento y evaluaciÃ³n de MLP, RNN y LSTM con sliding windows\n",
    "\n",
    "def sliding_window_regression_models_scaling_keras_rnn(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14],\n",
    "    test_window=1,\n",
    "    model_types=['MLP', 'RNN', 'LSTM'],\n",
    "    mlp_params={\n",
    "        'hidden_layers': [[16], [32], [64]],\n",
    "        'activation': ['relu'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    rnn_params={\n",
    "        'hidden_units': [16, 32],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    lstm_params={\n",
    "        'hidden_units': [32, 64],\n",
    "        'activation': ['tanh'],\n",
    "        'learning_rate': [0.001],\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32]\n",
    "    },\n",
    "    save_path='./progreso_keras_rnn'\n",
    "):\n",
    "    # Crea carpeta de resultados si no existe\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    # Itera sobre diferentes ventanas de entrenamiento T\n",
    "    for T in tqdm(T_values, desc=\"Procesando ventanas T\", unit=\"ventana\"):\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - T_hours - test_hours + 1\n",
    "        output_path = os.path.join(save_path, f'ANN_resultados_T{T}.csv')\n",
    "\n",
    "        # Carga resultados previos si existen para evitar cÃ¡lculos redundantes\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # Itera sobre MLP, RNN o LSTM\n",
    "        for model_type in model_types:\n",
    "            if model_type == 'MLP':\n",
    "                param_grid = list(product(*mlp_params.values()))\n",
    "                param_keys = list(mlp_params.keys())\n",
    "            elif model_type == 'RNN':\n",
    "                param_grid = list(product(*rnn_params.values()))\n",
    "                param_keys = list(rnn_params.keys())\n",
    "            elif model_type == 'LSTM':\n",
    "                param_grid = list(product(*lstm_params.values()))\n",
    "                param_keys = list(lstm_params.keys())\n",
    "\n",
    "            # Itera sobre combinaciones de hiperparÃ¡metros\n",
    "            for combo in param_grid:\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                print(f\"ðŸ”§ Evaluando modelo {model_type} con hiperparÃ¡metros: {param_dict}\")\n",
    "                param_dict = dict(zip(param_keys, combo))\n",
    "                if not df_prev.empty and (df_prev['modelo'] == model_type) & (df_prev['params'].apply(lambda p: p == param_dict)).any():\n",
    "                    continue\n",
    "\n",
    "                resultados = {k: [] for k in ['MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p']}\n",
    "\n",
    "                # Sliding window sobre el conjunto de datos\n",
    "                for start in range(0, total_windows, 24):\n",
    "                    if model_type == 'MLP':\n",
    "                        train = df.iloc[start: start + T_hours]\n",
    "                        test = df.iloc[start + T_hours: start + T_hours + test_hours]\n",
    "\n",
    "                        X_train = train.drop(columns=[target_col])\n",
    "                        y_train = train[target_col]\n",
    "                        X_test = test.drop(columns=[target_col])\n",
    "                        y_test = test[target_col]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train = scaler.fit_transform(X_train)\n",
    "                        X_test = scaler.transform(X_test)\n",
    "\n",
    "                        model = build_mlp_model(\n",
    "                            input_dim=X_train.shape[1],\n",
    "                            hidden_layers=param_dict['hidden_layers'],\n",
    "                            activation=param_dict['activation'],\n",
    "                            learning_rate=param_dict['learning_rate']\n",
    "                        )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    else:\n",
    "                        # Escalamiento sin data leakage para RNN/LSTM\n",
    "                        data_window = df.iloc[start: start + T_hours + test_hours].copy()\n",
    "                        train_data = data_window.iloc[:T_hours]\n",
    "                        test_data = data_window.iloc[T_hours:]\n",
    "\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_scaled = scaler.fit_transform(train_data.drop(columns=[target_col]))\n",
    "                        X_test_scaled = scaler.transform(test_data.drop(columns=[target_col]))\n",
    "\n",
    "                        train_scaled = pd.DataFrame(X_train_scaled, columns=train_data.columns.drop(target_col))\n",
    "                        train_scaled[target_col] = train_data[target_col].values\n",
    "\n",
    "                        test_scaled = pd.DataFrame(X_test_scaled, columns=test_data.columns.drop(target_col))\n",
    "                        test_scaled[target_col] = test_data[target_col].values\n",
    "\n",
    "                        scaled = pd.concat([train_scaled, test_scaled])\n",
    "                        X, y = create_rnn_sequences(scaled, target_col, T_hours)\n",
    "                        X_train, y_train = X[:-1], y[:-1]\n",
    "                        X_test, y_test = X[-1:], y[-1:]\n",
    "\n",
    "                        if model_type == 'RNN':\n",
    "                            model = build_rnn_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "                        else:  # LSTM\n",
    "                            model = build_lstm_model(\n",
    "                                timesteps=X_train.shape[1],\n",
    "                                input_dim=X_train.shape[2],\n",
    "                                hidden_units=param_dict['hidden_units'],\n",
    "                                activation=param_dict['activation'],\n",
    "                                learning_rate=param_dict['learning_rate']\n",
    "                            )\n",
    "\n",
    "                        early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "                        model.fit(X_train, y_train, epochs=param_dict['epochs'], batch_size=param_dict['batch_size'], verbose=0, callbacks=[early_stop])\n",
    "                        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "                    # CÃ¡lculo de mÃ©tricas\n",
    "                    residuals = y_test.values - y_pred if hasattr(y_test, 'values') else y_test - y_pred\n",
    "                    resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                    resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                    resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                    resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                    resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "                    if model_type == 'MLP' and len(residuals) >= 2:\n",
    "                        ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                    else:\n",
    "                        ljung_p = np.nan\n",
    "                    resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "                # Registro y guardado de resultados por combinaciÃ³n\n",
    "                nuevo_row = pd.DataFrame([{\n",
    "                    'modelo': model_type,\n",
    "                    'params': param_dict,\n",
    "                    'T_dias': T,\n",
    "                    'T_horas': T_hours,\n",
    "                    'MAPE': np.mean(resultados['MAPE']),\n",
    "                    'MAE': np.mean(resultados['MAE']),\n",
    "                    'RMSE': np.mean(resultados['RMSE']),\n",
    "                    'MSE': np.mean(resultados['MSE']),\n",
    "                    'R2': np.mean(resultados['R2']),\n",
    "                    'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "                }])\n",
    "                df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "                print(f\"âœ… Finalizado {model_type} con RMSE promedio: {np.mean(resultados['RMSE']):.4f}\")\n",
    "                df_prev.to_csv(output_path, index=False)\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando ventanas T:   0%|          | 0/2 [00:00<?, ?ventana/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Evaluando modelo MLP con hiperparÃ¡metros: {'hidden_layers': [16], 'activation': 'relu', 'learning_rate': 0.001, 'epochs': 50, 'batch_size': 32}\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029BF1ACE4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029BCEB5CC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "resultados_por_T = sliding_window_regression_models_scaling_keras_rnn(df, target_col='WIND_VEL_HOR')\n",
    "\n",
    "# Ver los DataFrames en memoria\n",
    "df_w_7 = resultados_por_T[7]    # Para T=7 dÃ­as\n",
    "df_w_14 = resultados_por_T[14]    # Para T=7 dÃ­as\n",
    "df_w_21 = resultados_por_T[21]    # Para T=7 dÃ­as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por RMSE de mayor a menor\n",
    "df_w_7_sorted = df_w_7.sort_values(by=\"RMSE\", ascending=True)\n",
    "\n",
    "# Etiquetas combinadas modelo + params\n",
    "etiquetas = df_w_7_sorted['modelo'].astype(str) + ' ' + df_w_7_sorted['params'].astype(str)\n",
    "\n",
    "# Crear la grÃ¡fica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(etiquetas, df_w_7_sorted['RMSE'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE por Modelo - T=7 dÃ­as (ordenado de mayor a menor)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighboors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que normalizar datos por eso se hace por aparte\n",
    "\n",
    "En principio, hay dos parÃ¡metros importantes en el clasificador KNeighbors: el nÃºmero de vecinos y cÃ³mo se mide la distancia entre los puntos de datos. En la prÃ¡ctica, utilizar un nÃºmero pequeÃ±o de vecinos, como tres o cinco, suele funcionar bien, pero se deberÃ­a ajustar este parÃ¡metro.\n",
    "\n",
    "La elecciÃ³n de la medida de distancia correcta es tambiÃ©n crucial. Por defecto, KNeighbors utiliza la distancia euclidiana, que funciona bien en muchos casos. Uno de los puntos fuertes de \n",
    "-NN es que el modelo es muy fÃ¡cil de entender, y a menudo da un rendimiento razonable sin necesidad de muchos ajustes. El uso de este algoritmo es un buen mÃ©todo de referencia para probar, antes de considerar tÃ©cnicas mÃ¡s avanzadas.\n",
    "\n",
    "La construcciÃ³n del modelo de vecinos mÃ¡s cercanos suele ser muy rÃ¡pida, pero cuando el conjunto de entrenamiento es muy grande (ya sea en nÃºmero de caracterÃ­sticas o en nÃºmero de muestras) la predicciÃ³n puede ser lenta. Cuando se utiliza el algoritmo \n",
    "-NN, es importante pre-procesar los datos, tema que revisaremos en secciones posteriores. Este enfoque no suele funcionar bien en conjuntos de datos con muchas caracterÃ­sticas (cientos o mÃ¡s), y lo hace especialmente mal con conjuntos de datos en los que la mayorÃ­a de las caracterÃ­sticas son 0 la mayor parte del tiempo (los llamados conjuntos de datos dispersos).\n",
    "\n",
    "Por lo tanto, aunque el algoritmo de \n",
    "-vecinos mÃ¡s cercanos es fÃ¡cil de entender, no se utiliza a menudo en la prÃ¡ctica, debido a que la predicciÃ³n es lenta y a su incapacidad para manejar muchas caracterÃ­sticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dudas para el profesor\n",
    "\n",
    "1. El fit del escalador se debe realizar con los datos de train, y con ese trabajar tanto train como test? Como se hace en producciÃ³n??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
