{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_lagged_features(\n",
    "    df: pd.DataFrame,\n",
    "    response_col: str,\n",
    "    num_lags: int,\n",
    "    response_shift: int = 0,\n",
    "    output_path: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con caracterÃ­sticas de retardo (lag features) para modelado,\n",
    "    y opcionalmente lo exporta a un archivo Excel, permitiendo desplazar la variable de respuesta.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original que contiene las columnas de respuesta y predictoras.\n",
    "        El Ã­ndice debe estar ordenado temporalmente.\n",
    "\n",
    "    response_col : str\n",
    "        Nombre de la columna que se utilizarÃ¡ como variable de respuesta.\n",
    "\n",
    "    num_lags : int\n",
    "        NÃºmero de perÃ­odos de retardo a considerar para las caracterÃ­sticas.\n",
    "\n",
    "    response_shift : int, opcional (por defecto 0)\n",
    "        NÃºmero de perÃ­odos para desplazar la variable de respuesta.\n",
    "        - Si es positivo, desplaza la respuesta hacia el futuro (predice el futuro).\n",
    "        - Si es negativo, desplaza la respuesta hacia el pasado.\n",
    "        - Si es 0, no se desplaza la respuesta.\n",
    "\n",
    "    output_path : str, opcional (por defecto None)\n",
    "        Ruta completa donde se exportarÃ¡ el DataFrame resultante en formato Excel.\n",
    "        Si es None, no se exportarÃ¡ el archivo.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las caracterÃ­sticas de retardo y la variable de respuesta.\n",
    "        Las filas con valores faltantes serÃ¡n eliminadas.\n",
    "    \"\"\"\n",
    "\n",
    "    if response_col not in df.columns:\n",
    "        raise ValueError(f\"La columna de respuesta '{response_col}' no estÃ¡ en el DataFrame.\")\n",
    "\n",
    "    # Determinar automÃ¡ticamente las columnas predictoras\n",
    "    predictor_cols = df.columns.drop(response_col)\n",
    "\n",
    "    # Crear DataFrame para caracterÃ­sticas de retardo\n",
    "    lag_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in predictor_cols:\n",
    "        for lag in range(1, num_lags + 1):\n",
    "            lag_features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    final_df = lag_features.copy()\n",
    "\n",
    "    # Agregar variable de respuesta desplazada\n",
    "    if response_shift != 0:\n",
    "        final_df[response_col] = df[response_col].shift(-response_shift + 1)\n",
    "    else:\n",
    "        final_df[response_col] = df[response_col]\n",
    "\n",
    "    # Eliminar valores faltantes y resetear Ã­ndice\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Exportar si se especifica una ruta\n",
    "    if output_path:\n",
    "        try:\n",
    "            directory = os.path.dirname(output_path)\n",
    "            if directory:\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "            final_df.to_excel(output_path, index=False)\n",
    "            print(f\"El DataFrame con caracterÃ­sticas de retardo ha sido exportado exitosamente a: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al exportar el DataFrame a Excel: {e}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 15, 50, 100], 'min_samples_leaf': [1, 10, 20]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': None},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100, 500], 'max_depth': [5, 10, 20], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01, 0.1], 'n_estimators': [100, 500]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nðŸ§ª Ventana T = {T} dÃ­as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'ðŸ˜Ž Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'14_21_resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # âš¡ Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # ðŸ§  Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # ðŸ” Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"âœ“ Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"ðŸ“¦ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"âœ” Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[14,21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15, 30], 'min_samples_leaf': [1, 3, 5, 10]}},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100], 'max_depth': [5], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01], 'n_estimators': [100]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.iloc[0:(24*7)*2]\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "num_lags = 24*7\n",
    "lagged = create_shifted_lagged_features(df_temp,response_col,num_lags,response_shift=1)\n",
    "lagged.to_csv('./lagged.csv', index=False)\n",
    "\n",
    "#T =[7,14,21]\n",
    "T =[14,21]\n",
    "test_window = 1\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "for t in T:\n",
    "  # Definir la ventana de tiempo para el entrenamiento y la prueba\n",
    "  T_hours = t * 24\n",
    "  test_hours = test_window * 24\n",
    "  extra = 24 #1 dia adicional para el test\n",
    "  total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "\n",
    "\n",
    "  splits=[]\n",
    "  for start in range(0,total_windows,24):\n",
    "    data_window = df.iloc[start: start + (T_hours * 2) + test_hours].copy()\n",
    "    temp_df = create_shifted_lagged_features(data_window,response_col,num_lags=T_hours,response_shift=1)\n",
    "    splits.append(temp_df)\n",
    "  \n",
    "splits[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
