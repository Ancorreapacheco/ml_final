{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA (UTC)</th>\n",
       "      <th>VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))</th>\n",
       "      <th>VENTO, VELOCIDADE HORARIA (m/s)</th>\n",
       "      <th>UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)</th>\n",
       "      <th>UMIDADE RELATIVA DO AR, HORARIA (%)</th>\n",
       "      <th>PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)</th>\n",
       "      <th>PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)</th>\n",
       "      <th>VENTO, RAJADA MAXIMA (m/s)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)</th>\n",
       "      <th>PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HORA (UTC)  VENTO, DIREÃ¯Â¿Â½Ã¯Â¿Â½O HORARIA (gr) (Ã¯Â¿Â½ (gr))  \\\n",
       "0      12:00                                    0.809017   \n",
       "\n",
       "   VENTO, VELOCIDADE HORARIA (m/s)  UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)  \\\n",
       "0                              1.8                                      69.0   \n",
       "\n",
       "   UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)  \\\n",
       "0                                      60.0   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½XIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            22.6   \n",
       "\n",
       "   TEMPERATURA MÃ¯Â¿Â½NIMA NA HORA ANT. (AUT) (Ã¯Â¿Â½C)  \\\n",
       "0                                            20.7   \n",
       "\n",
       "   UMIDADE RELATIVA DO AR, HORARIA (%)  \\\n",
       "0                                 61.0   \n",
       "\n",
       "   PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)  \\\n",
       "0                                              888.2       \n",
       "\n",
       "   PRECIPITAÃ¯Â¿Â½Ã¯Â¿Â½O TOTAL, HORÃ¯Â¿Â½RIO (mm)  VENTO, RAJADA MAXIMA (m/s)  \\\n",
       "0                                     0.0                         3.8   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)  \\\n",
       "0                                              888.2   \n",
       "\n",
       "   PRESSÃ¯Â¿Â½O ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)  \n",
       "0                                              887.7   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/data_treino_dv_df_2000_2010.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HORA</th>\n",
       "      <th>WIND_DIR_HOR</th>\n",
       "      <th>WIND_VEL_HOR</th>\n",
       "      <th>HUM_REL_MAX_ANT</th>\n",
       "      <th>HUM_REL_MIN_ANT</th>\n",
       "      <th>TEMP_MAX_ANT</th>\n",
       "      <th>TEMP_MIN_ANT</th>\n",
       "      <th>HUM_REL_HOR</th>\n",
       "      <th>PRES_ATM_NIV</th>\n",
       "      <th>PREC_HOR</th>\n",
       "      <th>RAFAGA_VIENTO</th>\n",
       "      <th>PRES_ATM_MAX_ANT</th>\n",
       "      <th>PRES_ATM_MIN_ANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>888.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>888.2</td>\n",
       "      <td>887.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13:00</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>888.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>888.4</td>\n",
       "      <td>888.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HORA  WIND_DIR_HOR  WIND_VEL_HOR  HUM_REL_MAX_ANT  HUM_REL_MIN_ANT  \\\n",
       "0  12:00      0.809017           1.8             69.0             60.0   \n",
       "1  13:00      0.965926           2.7             62.0             55.0   \n",
       "\n",
       "   TEMP_MAX_ANT  TEMP_MIN_ANT  HUM_REL_HOR  PRES_ATM_NIV  PREC_HOR  \\\n",
       "0          22.6          20.7         61.0         888.2       0.0   \n",
       "1          24.2          22.5         55.0         888.4       0.0   \n",
       "\n",
       "   RAFAGA_VIENTO  PRES_ATM_MAX_ANT  PRES_ATM_MIN_ANT  \n",
       "0            3.8             888.2             887.7  \n",
       "1            4.7             888.4             888.2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['HORA','WIND_DIR_HOR','WIND_VEL_HOR','HUM_REL_MAX_ANT','HUM_REL_MIN_ANT','TEMP_MAX_ANT','TEMP_MIN_ANT','HUM_REL_HOR','PRES_ATM_NIV','PREC_HOR','RAFAGA_VIENTO','PRES_ATM_MAX_ANT','PRES_ATM_MIN_ANT']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='HORA', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_lagged_features(\n",
    "    df: pd.DataFrame,\n",
    "    response_col: str,\n",
    "    num_lags: int,\n",
    "    response_shift: int = 0,\n",
    "    output_path: str = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con caracterÃ­sticas de retardo (lag features) para modelado,\n",
    "    y opcionalmente lo exporta a un archivo Excel, permitiendo desplazar la variable de respuesta.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original que contiene las columnas de respuesta y predictoras.\n",
    "        El Ã­ndice debe estar ordenado temporalmente.\n",
    "\n",
    "    response_col : str\n",
    "        Nombre de la columna que se utilizarÃ¡ como variable de respuesta.\n",
    "\n",
    "    num_lags : int\n",
    "        NÃºmero de perÃ­odos de retardo a considerar para las caracterÃ­sticas.\n",
    "\n",
    "    response_shift : int, opcional (por defecto 0)\n",
    "        NÃºmero de perÃ­odos para desplazar la variable de respuesta.\n",
    "        - Si es positivo, desplaza la respuesta hacia el futuro (predice el futuro).\n",
    "        - Si es negativo, desplaza la respuesta hacia el pasado.\n",
    "        - Si es 0, no se desplaza la respuesta.\n",
    "\n",
    "    output_path : str, opcional (por defecto None)\n",
    "        Ruta completa donde se exportarÃ¡ el DataFrame resultante en formato Excel.\n",
    "        Si es None, no se exportarÃ¡ el archivo.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con las caracterÃ­sticas de retardo y la variable de respuesta.\n",
    "        Las filas con valores faltantes serÃ¡n eliminadas.\n",
    "    \"\"\"\n",
    "\n",
    "    if response_col not in df.columns:\n",
    "        raise ValueError(f\"La columna de respuesta '{response_col}' no estÃ¡ en el DataFrame.\")\n",
    "\n",
    "    # Determinar automÃ¡ticamente las columnas predictoras\n",
    "    predictor_cols = df.columns.drop(response_col)\n",
    "\n",
    "    # Crear DataFrame para caracterÃ­sticas de retardo\n",
    "    lag_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in predictor_cols:\n",
    "        for lag in range(1, num_lags + 1):\n",
    "            lag_features[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # Construir DataFrame final\n",
    "    final_df = lag_features.copy()\n",
    "\n",
    "    # Agregar variable de respuesta desplazada\n",
    "    if response_shift != 0:\n",
    "        final_df[response_col] = df[response_col].shift(-response_shift + 1)\n",
    "    else:\n",
    "        final_df[response_col] = df[response_col]\n",
    "\n",
    "    # Eliminar valores faltantes y resetear Ã­ndice\n",
    "    final_df.dropna(inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Exportar si se especifica una ruta\n",
    "    if output_path:\n",
    "        try:\n",
    "            directory = os.path.dirname(output_path)\n",
    "            if directory:\n",
    "                os.makedirs(directory, exist_ok=True)\n",
    "            final_df.to_excel(output_path, index=False)\n",
    "            print(f\"El DataFrame con caracterÃ­sticas de retardo ha sido exportado exitosamente a: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al exportar el DataFrame a Excel: {e}\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7, 14, 21],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15, 30, 50, 100], 'min_samples_leaf': [1, 3, 5, 10, 15, 20]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': None},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100, 300, 500], 'max_depth': [5, 10, 15, 30], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3], 'n_estimators': [100, 300, 500]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    resultados_por_T = {}\n",
    "\n",
    "    for T in tqdm(T_values, desc=\"Procesando T\", unit=\"ventana\", leave=True):\n",
    "        print(f\"\\nðŸ§ª Ventana T = {T} dÃ­as\")\n",
    "        T_hours = T * 24\n",
    "        test_hours = test_window * 24\n",
    "        total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "        print(f'ðŸ˜Ž Total windows {total_windows}')\n",
    "\n",
    "        output_path = os.path.join(save_path, f'resultados_T{T}.csv')\n",
    "        split_dir = os.path.join(save_path, f'splits_T{T}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            df_prev = pd.read_csv(output_path)\n",
    "            if 'params' in df_prev:\n",
    "                df_prev['params'] = df_prev['params'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (None if pd.isna(x) else x)\n",
    "                )\n",
    "        else:\n",
    "            df_prev = pd.DataFrame(columns=[\n",
    "                'modelo', 'params', 'T_dias', 'T_horas', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2', 'LjungBox_p'\n",
    "            ])\n",
    "\n",
    "        # âš¡ Generar o cargar splits desde .npz\n",
    "        splits = []\n",
    "        for i, start in enumerate(tqdm(range(0, total_windows, 24), desc=\"Generando splits\", leave=True)):\n",
    "            split_file = os.path.join(split_dir, f'split_{i}.npz')\n",
    "\n",
    "            if os.path.exists(split_file):\n",
    "                data = np.load(split_file, allow_pickle=True)\n",
    "                X_train, y_train, X_test, y_test = data['X_train'], data['y_train'], data['X_test'], data['y_test']\n",
    "            else:\n",
    "                data_window = df.iloc[start: start + (2 * T_hours) + test_hours].copy()\n",
    "\n",
    "                temp_df = create_shifted_lagged_features(\n",
    "                    data_window,\n",
    "                    response_col=target_col,\n",
    "                    num_lags=T_hours,\n",
    "                    response_shift=1\n",
    "                )\n",
    "\n",
    "                train = temp_df.iloc[:-test_hours]\n",
    "                test = temp_df.iloc[-test_hours:]\n",
    "\n",
    "                X_train = train.drop(columns=[target_col]).values\n",
    "                y_train = train[target_col].values\n",
    "                X_test = test.drop(columns=[target_col]).values\n",
    "                y_test = test[target_col].values\n",
    "\n",
    "                np.savez_compressed(split_file,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "\n",
    "            splits.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "        # ðŸ§  Crear modelos\n",
    "        models = []\n",
    "        for modelo in tqdm(modelos, desc=\"Construyendo modelos\", leave=False):\n",
    "            model_name = modelo['name']\n",
    "            ModelClass = modelo['ModelClass']\n",
    "            param_grid = modelo['params']\n",
    "\n",
    "            if param_grid is None:\n",
    "                models.append({'name': model_name, 'model': ModelClass(), 'params': True})\n",
    "            else:\n",
    "                for combo in product(*param_grid.values()):\n",
    "                    param_dict = dict(zip(param_grid.keys(), combo))\n",
    "                    model_instance = ModelClass(**param_dict)\n",
    "                    models.append({\n",
    "                        'name': model_name,\n",
    "                        'model': model_instance,\n",
    "                        'params': param_dict\n",
    "                    })\n",
    "\n",
    "        # ðŸ” Evaluar modelos\n",
    "        for m in tqdm(models, desc=\"Evaluando modelos\", leave=True):\n",
    "            ya_evaluado = ((df_prev['modelo'] == m['name']) &\n",
    "                           (df_prev['params'].apply(lambda p: p == m['params']))).any()\n",
    "\n",
    "            if not df_prev.empty and ya_evaluado:\n",
    "                print(f\"âœ“ Modelo {m['name']} con {m['params']} ya evaluado para T={T}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            resultados = {\n",
    "                'modelo': m['name'],\n",
    "                'params': m['params'],\n",
    "                'T_dias': T,\n",
    "                'T_horas': T_hours,\n",
    "                'MAPE': [],\n",
    "                'MAE': [],\n",
    "                'RMSE': [],\n",
    "                'MSE': [],\n",
    "                'R2': [],\n",
    "                'LjungBox_p': []\n",
    "            }\n",
    "\n",
    "            for X_train, y_train, X_test, y_test in tqdm(splits, desc=f\"{m['name']} (T={T}d)\", leave=True):\n",
    "                model = m['model']\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                residuals = y_test - y_pred\n",
    "\n",
    "                resultados['MAPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "                resultados['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "                resultados['RMSE'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "                resultados['MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "                resultados['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "                if len(residuals) >= 2:\n",
    "                    ljung_p = acorr_ljungbox(residuals, lags=[1], return_df=True)['lb_pvalue'].iloc[0]\n",
    "                else:\n",
    "                    ljung_p = np.nan\n",
    "\n",
    "                resultados['LjungBox_p'].append(ljung_p)\n",
    "\n",
    "            nuevo_row = pd.DataFrame([{\n",
    "                'modelo': resultados['modelo'],\n",
    "                'params': resultados['params'],\n",
    "                'T_dias': resultados['T_dias'],\n",
    "                'T_horas': resultados['T_horas'],\n",
    "                'MAPE': np.mean(resultados['MAPE']),\n",
    "                'MAE': np.mean(resultados['MAE']),\n",
    "                'RMSE': np.mean(resultados['RMSE']),\n",
    "                'MSE': np.mean(resultados['MSE']),\n",
    "                'R2': np.mean(resultados['R2']),\n",
    "                'LjungBox_p': np.nanmean(resultados['LjungBox_p'])\n",
    "            }])\n",
    "\n",
    "            df_prev = pd.concat([df_prev, nuevo_row], ignore_index=True)\n",
    "            df_prev.to_csv(output_path, index=False)\n",
    "            print(f\"ðŸ“¦ Guardado modelo {m['name']} con {m['params']} en T={T}\")\n",
    "\n",
    "        resultados_por_T[T] = df_prev\n",
    "        print(f\"âœ” Resultados finales guardados en: {output_path}\")\n",
    "\n",
    "    return resultados_por_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164ee1432a4a40919535133ce0064b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando T:   0%|          | 0/1 [00:00<?, ?ventana/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Ventana T = 7 dÃ­as\n",
      "ðŸ˜Ž Total windows 87334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe36c57479424ca3858178b631a017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando splits:   0%|          | 0/3639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_regression_models_lagged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWIND_VEL_HOR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLinearRegression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mridge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRidge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit_intercept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlasso\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLasso\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit_intercept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtree_regressor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDecisionTreeRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_samples_leaf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mramdon_forest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_jobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb_regressor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mGradientBoostingRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./progreso\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 48\u001b[0m, in \u001b[0;36msliding_window_regression_models_lagged\u001b[1;34m(df, target_col, T_values, test_window, modelos, save_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m split_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(split_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(split_file):\n\u001b[1;32m---> 48\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\numpy\\lib\\npyio.py:444\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic\u001b[38;5;241m.\u001b[39mstartswith(_ZIP_PREFIX) \u001b[38;5;129;01mor\u001b[39;00m magic\u001b[38;5;241m.\u001b[39mstartswith(_ZIP_SUFFIX):\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;66;03m# zip-file (assume .npz)\u001b[39;00m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Potentially transfer file ownership to NpzFile\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     stack\u001b[38;5;241m.\u001b[39mpop_all()\n\u001b[1;32m--> 444\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mNpzFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mown_fid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mown_fid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# .npy file\u001b[39;00m\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\numpy\\lib\\npyio.py:190\u001b[0m, in \u001b[0;36mNpzFile.__init__\u001b[1;34m(self, fid, own_fid, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fid, own_fid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    186\u001b[0m              pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    187\u001b[0m              max_header_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39m_MAX_HEADER_SIZE):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;66;03m# Import is postponed to here since zipfile depends on gzip, an\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# optional component of the so-called standard library.\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     _zip \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_files \u001b[38;5;241m=\u001b[39m _zip\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\site-packages\\numpy\\lib\\npyio.py:103\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m    102\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowZip64\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\zipfile.py:1268\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1268\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\zipfile.py:1331\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m \u001b[43m_EndRecData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\PROGRAMS\\Miniconda\\envs\\ml_venv\\lib\\zipfile.py:273\u001b[0m, in \u001b[0;36m_EndRecData\u001b[1;34m(fpin)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfpin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m sizeEndCentDir \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    275\u001b[0m     data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m stringEndArchive \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# the signature is correct and there's no comment, unpack structure\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(structEndArchive, data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = sliding_window_regression_models_lagged(\n",
    "    df,\n",
    "    target_col='WIND_VEL_HOR',\n",
    "    T_values=[7],\n",
    "    test_window=1,\n",
    "    modelos=[\n",
    "        {'name': 'lr', 'ModelClass': LinearRegression, 'params': None},\n",
    "        {'name': 'ridge', 'ModelClass': Ridge, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'lasso', 'ModelClass': Lasso, 'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0], 'fit_intercept': [True, False]}},\n",
    "        {'name': 'tree_regressor', 'ModelClass': DecisionTreeRegressor, 'params': {'max_depth': [5, 10, 15, 30], 'min_samples_leaf': [1, 3, 5, 10]}},\n",
    "        {'name': 'ramdon_forest', 'ModelClass': RandomForestRegressor, 'params': {'n_estimators': [100], 'max_depth': [5], 'n_jobs': [-1]}},\n",
    "        {'name': 'xgb_regressor', 'ModelClass': GradientBoostingRegressor, 'params': {'random_state': [0], 'learning_rate': [0.01], 'n_estimators': [100]}}\n",
    "    ],\n",
    "    save_path='./progreso'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.iloc[0:(24*7)*2]\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "num_lags = 24*7\n",
    "lagged = create_shifted_lagged_features(df_temp,response_col,num_lags,response_shift=1)\n",
    "lagged.to_csv('./lagged.csv', index=False)\n",
    "\n",
    "#T =[7,14,21]\n",
    "T =[14]\n",
    "test_window = 1\n",
    "response_col = 'WIND_VEL_HOR'\n",
    "for t in T:\n",
    "  # Definir la ventana de tiempo para el entrenamiento y la prueba\n",
    "  T_hours = t * 24\n",
    "  test_hours = test_window * 24\n",
    "  extra = 24 #1 dia adicional para el test\n",
    "  total_windows = len(df) - (2 * T_hours) - test_hours + 1\n",
    "\n",
    "\n",
    "  splits=[]\n",
    "  for start in range(0,total_windows,24):\n",
    "    data_window = df.iloc[start: start + (T_hours * 2) + test_hours].copy()\n",
    "    temp_df = create_shifted_lagged_features(data_window,response_col,num_lags=T_hours,response_shift=1)\n",
    "    splits.append(temp_df)\n",
    "  \n",
    "splits[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
